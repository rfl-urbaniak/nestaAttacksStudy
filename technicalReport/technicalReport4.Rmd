---
title: "Bayesian analysis of the NESTA study of interventions against  verbal aggression online \\linebreak  Technical Report"
author: "Rafal Urbaniak"
output:
  pdf_document:
  number_sections: yes
df_print: kable
keep_tex: yes
includes:
  in_header: Rafal_latex7.sty
html_document:
  df_print: paged
word_document: default
classoption: dvipsnames, enabledeprecatedfontcommands
fontsize: 10pt
documentclass: scrartcl
urlcolor: blue
bibliography: ../references/attacks.bib
csl: ../references/apa-6th-edition.csl
---
  
  
```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = '../')

#libraries used
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(kableExtra)
library(viridis)
library(rethinking)
library(ggplot2)
library(ggpubr)
library(tidyverse)
library(GGally)
library(dagitty)
library(reshape)
library(lubridate)
library(formatR)



mykable <- function(object) {kable(object, "latex", booktabs = T,linesep = "") %>% kable_styling(latex_options = "striped",font_size = 9)}  

removeX <-   theme(axis.title.x=element_blank(),
                   axis.text.x=element_blank(),
                   axis.ticks.x=element_blank())

removeY <-   theme(axis.title.y=element_blank(),
                   axis.text.y=element_blank(),
                   axis.ticks.y=element_blank())

knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 70), tidy = TRUE)

#kable(table(data$group), "latex", booktabs = T, col.names = c("Group", "n")) %>% 
#  kable_styling(latex_options = c("striped","HOLD_position"),font_size = 9) 
```



\tableofcontents






# Data and exploration




\vspace{1mm}
\scriptsize

```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE, tidy = TRUE}
Hate <- readRDS(file = "datasets/RAWNESTA/Hate.rds")
Comments <-   readRDS(file = "datasets/RAWNESTA/Comments.rds")
summaries <- read.csv(file = "datasets/Summaries.csv")

dates <- colnames(Hate)[-1]
dates <- as.Date(dates)
startDate <- dates[1]
interventionDate <- "2020-07-08"
observationDate <- "2020-09-09"
end <- dates[length(dates)]

periods<- numeric(length(dates))
periods <- ifelse(dates < interventionDate,"pre-treatment",periods)
periods <- ifelse(dates >= interventionDate & dates < observationDate,"treatment",periods)
periods <- ifelse(dates >= observationDate,"post-treatment",periods)

hateTS <- as.data.frame(colSums(Hate[,-1]))
hateTS$date <- as.Date(rownames(hateTS))
rownames(hateTS) <- NULL
colnames(hateTS) <- c("attacks","date")
hateTS$periods <- periods

interventions <- readRDS(file = "datasets/interventions.rds")
interventionsTS <- as.data.frame(table(interventions$day))
interventionsTS$Var1 <- as.Date(interventionsTS$Var1)
colnames(interventionsTS) <- c("date", "interventions")

periodsDF <- merge(x = hateTS, y = interventionsTS, by = "date", all.x = TRUE)

idx <- c(1, diff(periodsDF$date))
i2 <- c(1,which(idx != 1), nrow(periodsDF)+1)
periodsDF$grp <- rep(1:length(diff(i2)), diff(i2))

periodsDF$interventions[is.na(periodsDF$interventions) & periodsDF$periods == "treatment"] <- 0

periodsPlot <- ggplot(periodsDF)+
  geom_line(aes(x=date, y = attacks, group = grp),
             alpha = 0.8, size = .6)+
  geom_line(aes(x=date, y = interventions, group = grp),
            alpha = 0.8, size = .6)+
  geom_vline(xintercept = startDate, lty =2, size =.2, alpha=0.5)+
  geom_vline(xintercept = as.Date(interventionDate), lty =2, size =.2, alpha=0.5)+
  geom_vline(xintercept =  as.Date(observationDate), lty = 2, size =.2, alpha=0.5 )+
  geom_vline(xintercept = as.Date(end), lty =2, size =.2, alpha=0.5)+
  labs(title = "Attacks and interventions time series",
       subtitle = "no line at data gaps", 
       caption = "days with data: 81 (pre-treatment), 62 (treatment), 72 (post-treatment)")+
  theme_tufte() + theme(axis.title.x=element_blank(), 
      plot.caption = element_text(hjust = 0.5,  face= "italic"))+
  scale_x_date(date_labels = "%b %d", breaks = c(startDate, as.Date(startDate), as.Date(interventionDate), as.Date(observationDate), end), 
               limits = c(startDate-30,end+10))+ylab("count")+
  annotate("rect", xmin = as.Date(interventionDate), xmax = as.Date(observationDate), ymin = -1, ymax = 360,
           alpha = .2,fill = "darkgreen")+ylim(c(-1,370))+
  annotate("text", label = "pre-treatment", x = as.Date(startDate)+2, y = 370, hjust =0 )+
  annotate("text", label = "treatment", x = as.Date(interventionDate)+2, y = 370, hjust =0 )+
  annotate("text", label = "post-treatment", x = as.Date(observationDate)+2, y = 370, hjust =0 )+
  annotate("text", label = "interventions:", x = as.Date(interventionDate)-55, y = 15, hjust =0 )+
  annotate("text", label = "attacks:", x = as.Date(startDate)-30, y = 215, hjust =0 )

periodsDF$weekdays <-  weekdays(as.Date(periodsDF$date))
periodsDF$weeks <-  week(as.Date(periodsDF$date))

periodsDF$weekdays <- as.factor(periodsDF$weekdays)
levels(periodsDF$weekdays) <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday",
                                "Saturday", "Sunday")
weeksPlot <- ggplot(periodsDF)+
  geom_smooth(aes(x = weekdays, y = attacks, group =1))+
  geom_line(aes(x = weekdays, y = attacks, group = weeks),alpha = 0.1)+
  theme_tufte()+labs(title="Personal attacks throught weekdays (six months)", subtitle = "No weekly patterns")+xlab("")+
  ylab("count")
```
\normalsize



For the duration of the project we selected `r length(unique(summaries$author))` Reddit users and tracked their activity (with some breaks resulting from API restrictions and technical issues, which were mostly sorted out in the observation period), starting on `r `startDate`, beginning the intervention period on `r interventionDate`, leading to a further observation period starting on  `r observationDate` and ending on  `r end`. The time series of attacks observed and of interventions conducted can be inspected in Figure \ref{fig:periodsPlot}.


\begin{figure}[H]
```{r periodsPlot,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
periodsPlot
```
\caption{Daily sums of attacks and interventions throughout the three experimental periods, with GAM smoothing (blue).}
\label{fig:periodsPlot}
\end{figure}


Interestingly, no weekly patterns of overall aggressive behavior seem apparent, as can be seen from plotting multiple weeks alongside, as in Figure \ref{fig:weeksPlot}.

\begin{figure}[H]
```{r weeksPlot,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
weeksPlot
```
\caption{Attack sums from all  weeks in the experimental period plotted against week days. No pattern seems to arise.}
\label{fig:weeksPlot}
\end{figure}


We analyzed the data from two perspective: we ran a before-and after analysis, comparing the summarized aggression levels before and after the intervention period (with various additional predictors), and a time-series perspective, which took a more fine-grained perspective. For now, we will focus on  the Bayesian before-and-after analysis, for which the data were  cleaned and converted into a summarized form, involving the variables listed in Table \ref{tab:baaVars}.


\vspace{1mm}
\footnotesize
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
variable <- c("AB", "AD", "AA", "CB", "CD", "CA", "group", "IC")
explanation <- c("attacks before (pre-treatment)", "attacks during (the treatment period)",
                 "attacks after (post-treatment)", "comments before", "comments during",
                 "comments after", "treatment group", "intervention count")
vars <- data.frame(variable, explanation)
#mykable(vars)
```
\normalsize


\begin{table}
\centering
\begin{tabular}{ll}
\toprule
variable & explanation\\
\midrule
\cellcolor{gray!6}{AB} & \cellcolor{gray!6}{attacks before (pre-treatment)}\\
AD & attacks during (the treatment period)\\
\cellcolor{gray!6}{AA} & \cellcolor{gray!6}{attacks after (post-treatment)}\\
CB & comments before\\
\cellcolor{gray!6}{CD} & \cellcolor{gray!6}{comments during}\\
CA & comments after\\
\cellcolor{gray!6}{group} & \cellcolor{gray!6}{treatment group}\\
IC & intervention count\\
\bottomrule
\end{tabular}

\caption{Variables involved in the before-and-after analysis.}
\label{tab:baaVars}
\end{table}





Further variables were defined in terms of those, in particular, we will be predicting \textsf{AdiffS} which is the standardized difference  \textsf{AA}-\textsf{AB}, and \textsf{AdiffS}, which is the standardized difference \textsf{CA}-\textsf{CB}. The predictors were also standardized (and named $\langle$variable\char`_name$\rangle$S),  and  a numerical index for the group (\textsf{groupID})  has been introduced. 

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
summaries$ABS <- standardize(summaries$AB)
summaries$CBS <- standardize(summaries$CB)
summaries$AAS <- standardize(summaries$AA)
summaries$CAS <- standardize(summaries$CA)
summaries$CDS <- standardize(summaries$CD)
summaries$ADS <- standardize(summaries$AD)
summaries$group <- as.factor(summaries$group)
summaries$groupID <-  as.integer( as.factor(summaries$group) )
```
\normalsize


The distribution of \textsf{IC} in the treatment groups is visualized in Figure \ref{fig:interventionsDistro}. Note that the distributions are somewhat different, even though the total intervention counts are similar (`r  colSums(table(summaries$IC, summaries$group))["empathy"]` for empathy and  `r colSums(table(summaries$IC, summaries$group))["normative"]` for normative). The issue is discussed in Section XXXXX. 


\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
interventionsDistro <- ggplot(summaries[summaries$group != "control",], aes(x = IC, fill = group))+
  geom_bar()+theme_tufte()+
  xlab("interventions received")+
  labs(title = "Intervention counts in treatment groups")+
  scale_x_continuous(breaks = seq(0,40,5))
```
\normalsize


\begin{figure}[H]
```{r interventionsDistro,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
interventionsDistro
```
\caption{Distribution of daily interventions, by treatment group.}
\label{fig:interventionsDistro}
\end{figure}


Second, when we look at the distribution of standardized difference in attacks, when restricted to (-1,1), the peaks of distributions are shifted a bit between the groups, with lowest median for the normative group, but the differences seem minor (Figure \ref{fig:violJoint}).  This might suggest no impact of the interventions, but this conclusion would be too hasty, as the impact of  other predictor variables and interactions involved can mask actual associations. We will take a closer look at this issue in our analysis.




\vspace{1mm}
\footnotesize
```{r violEmpiricalAdiff,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
violAdiffS <- ggplot(summaries, aes(x=group, y = AdiffS))+
  geom_violin() +theme_tufte() +theme(plot.title.position = "plot")
violJoint <- ggarrange(violAdiffS+ggtitle("whole range"),
              violAdiffS + ylim(c(-1,1))+geom_boxplot(width = .2)+
              ggtitle("restricted to (-1,1)"))   +theme(plot.title.position = "plot")
violJointTitled <- annotate_figure(violJoint, 
  top = text_grob("Empirical distribution of change in attacks (standardized)",
                  size = 12))
```
\normalsize


\begin{figure}[H]
```{r violJoint,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
violJointTitled
```
\caption{Empirical distribution of change in attacks, by treatment group.}
\label{fig:violJoint}
\end{figure}




To see how this masking can occur, let's inspect  changes in attacks against intervention counts. It turns out that  restricting attention to various aggression levels in fairly strong changes to  the regression lines (Figure \ref{fig:linearShift}).  This suggests we should keep an eye out for interactions in the analysis, and that the initial comparison of means or medians between groups might be misleading if the effects in different volume groups are different and cancel each other. 


\vspace{1mm}
\footnotesize
```{r ic,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
icplot1 <- ggplot(summaries, aes(x = IC, y = AdiffS, color = group, fill = group))+
  geom_jitter(alpha = 0.6, size =.8)+theme_tufte()+ theme(plot.title.position = "plot") +
  geom_smooth(alpha = 0.2, method = "lm")+
  xlim(c(0,25))+ylim(c(-2,2))+
  ggtitle("sd restricted to (-2,2)")+
  theme(legend.position = c(0.65, 0.2))

icplot2 <-  ggplot(summaries, aes(x = IC, y = AdiffS, color = group, fill = group))+
  geom_jitter(alpha = 0.6, size =.8)+theme_tufte()+theme(plot.title.position = "plot") +
  geom_smooth(alpha = 0.2, method = "lm")+
  xlim(c(0,25))+ylim(c(-1,1))+ggtitle("sd restricted to (-1,1)")+
  theme(legend.position = c(0.65, 0.2))


icplotJoint <- ggarrange(icplot1, icplot2) 
icplotTitled <- annotate_figure(icplotJoint, 
  top = text_grob("Change in attacks (standardized) vs interventions received",  size = 12))
```
\normalsize


\begin{figure}
```{r fig:linearShift,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
icplotTitled  
```
\caption{Change in attacks vs intervention counts by treatment group, jittered with  linear smoothing. Change of range of aggression levels results in different linear smoothings.}
\label{fig:linearShift}
\end{figure}


Let's now inspect  correlations between the variables involved in the model (Figure \ref{fig:correlations}). Almost no predictors are strongly correlated, except for  \textsf{CBS}, \textsf{CAS} and  \textsf{CDS}. We are not interested in using \textsf{CAS} as a predictor, as it occurs \emph{after} the interventions,  and we drop \textsf{CDS} from the analysis, generally   avoiding using these variables in the same model to avoid statistical issues resulting from multicolinearity. In fact, it is no surprise that  users' general activity in a period is   a decent proxy for their general activity in other periods.



\begin{figure}[H]
```{r correlations,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
summariesCorr <- select(summaries, IC, ABS, CBS, AAS, CAS, CDS, ADS)
ggcorr(summariesCorr, method = c("pairwise"),
       digits = 4, low = "steelblue", mid = "white",
       high = "darkred", midpoint =0,
       geom = "tile", label = TRUE, label_size=4, label_round =2, layout.exp =1,
       label_alpha = FALSE,hjust = 0.75)
```
\caption{Correlations between predictors used in the before-and-after analysis.}
\label{fig:correlations}
\end{figure}


# Causal inference and variable selection


To identify the right variables to condition (or not condition) on to identify the causal effect of the interventions, we first need to think about the causal structure of the problem. A plausible causal structure that we will be working with is visualized in Figure \ref{fig:causal}. Comments during impact attacks during, which trigger interventions.
Unmeasured user features cause comments before, which impact attacks before, and also    attacks before directly. Comments during (their impact on ADS is already included)  impact attacks during during directly and  comments after, which impact attacks after and   attacks after directly.  Intervention count impacts attacks after  and comments after. The same directions of impact are included for intervention type. Finally, comments through time are connected causally, and so are attacks.






\vspace{1mm}
\footnotesize
```{r dag1,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "80%"}
dag <- dagitty("
  dag{
  CDS -> ADS -> IC  
               U [unobserved]   
               U -> CBS -> ABS  
               U -> ABS        
               U -> CDS -> ADS  
               U -> ADS         
               U -> CAS -> AAS    
               U -> AAS                        
               IC -> AAS        
               IC -> CAS        
               IT -> CAS        
               IT -> AAS
               CBS -> CDS -> CAS
               ABS -> ADS -> AAS
               }")
coordinates( dag ) <- list( x=c(CBS=0,ABS=0,CDS=1,ADS=1, CAS = 2,
                    AAS = 2, IT = 1.5, IC = 1.5, U = .5) ,
y=c(CBS =0,ABS = 1,CDS = 0,ADS = 1, CAS = 0, AAS = 1, 
    IT = .3, IC = .7, U =.5) )
```
\normalsize



\begin{figure}[H]
```{r,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
drawdag(dag)  
```
\caption{A causal model used in the before-and-after analysis.}
\label{fig:causal}
\end{figure}



We already know not to condition on CDS if we condition on CAS or CBS (multicolinearity). What else can we learn from the causal model? \textsf{IT} has no backdoor paths, but \textsf{IC} does, so we need to make sure these are closed to avoid including spurious correlations in our analysis. There are in fact 65 different paths from \textsf{IC} to \textsf{AAC}. Crucially,  all backdoor paths go through \textsf{ADS}, which then becomes either a fork or a pipe, so all backdoor paths can be closed by conditioning on \textsf{ADS}. Moreover there is only one directed indirect path, it goes through \textsf{CAS}, so we should not condition on \textsf{CAS} if we are to identify total  causal effect of \textsf{IC} on attacks, including the impact  mediated by its impact on comments (unless we care about the direct effect of \textsf{IC}  and \textsf{IT} on \textsf{AAS}, but that's a separate question). This is in line with the adjustment set identified algorithmically using by the \textsf{dagitty} package. 

The situation is somewhat  different when it comes to evaluating the *direct* effect of intervention. Then, we also need to block indirect causal paths from the intervention to the outcome. For such an evaluation we need to also condition on \textsf{CAS}, which is what we will do when we turn to the study of the direct effects of the interventions. 



\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
paths(dag, from = c("IC"), to = "AAS")
adjustmentSets(dag, exposure = c("IC", "IT"), outcome = "AAS", type = "all")
```
\normalsize





In fact, we will be predicting the difference between attacks before and after, and the difference between comments, before and after, but the general points about the nodes involved apply also to defined nodes. Finding a maximal sensible set (canonical) of covariates suggests including \textsf{CDS} and \textsf{ABS}. As already discussed, we do not include \textsf{CDS} because of its strong correlation with \textsf{CBS}. We also do not condition on \textsf{ABS}---not only because it has a pretty strong correlation with another predictor (\textsf{ADS}), but rather mainly because it is used to define the output variable. In such a set-up, it is clear that a model including \textsf{ABS} would have better predictive power, but since a definitional connection is present, thinking that its inclusion in the model tells us something about causality  would be misled. 

Otherwise, it's open season for the  other variables and interactions between them, and our decision to include or exclude them in the model will be guided by information-theoretic criteria of predictive power.  
  
  
  
# Before-and-after analysis: bayesian model building


  
  
We build and compared  multiple additive models where the outcome variable is normally distributed around the predicted mean, which is a linear function of predictors (possibly with  interactions). Bayesian information criteria  (WAIC)\footnote{
Here's a more detailed explanation of the model comparison method we used, uninterested reader is invited to skip forward. Let  $y$ be the observations and $\Theta$  a posterior distribution.
First, log-pointwise-predictive-density is defined by:
\begin{align*}
\mathsf{lppd}(y, \Theta) & = \sum_i log\frac{1}{S}\sum_s p (y_i\vert \Theta_s)
\end{align*}
\noindent where $S$ is the number of samples in the posterior, and $\Theta_s$ 
is the $s$-th combination of sampled parameter values in the posterior distribution. That is, 
for each observation and each combination of 
parameters in the posterior we first compute its density, then 
we take the average density of that observation over all combinations of parameters in the posterior,
and  then take the logarithm. Finally, we sum these values up for all the observations. Crucially, when comparing posterior distributions with respect to the same dataset, \textsf{lppd}s are proportional
 to unbiased estimates of their divergence from the real distribution (note that it is \emph{only} 
 proportional, and for this reason can be used for comparison of distributions 
 only and makes no intuitive sense on its own).  However, \textsf{lppd} always improves
  as the model gets more complex, so for model comparison it makes more sense to use 
 the Widely Applicable Information Criterion (WAIC), which is an approximation of the out-of-sample deviance that converges to the cross-validation approximation in a large sample. It  is defined as
 the log-posterior-predictive-density with an additional
  penalty proportional to the variance in the
  posterior predictions:
  \begin{align*}
\mathsf{WAIC(y, \Theta)} & = -2 (\mathsf{lppd} - \overbrace{\sum_i var_\theta \mathsf{log} p (y_i \vert \theta)}^{\mathsf{penalty}})
  \end{align*}
\noindent  Thus to construct the penalty, we calculate the variance in log-probabilities for each observation and sum them up. Because of the analogy to Akaike's criterion, the penalty is sometimes called the effective number of parameters, $p_{\mathsf{WAIC}}$. 
How does WAIC compare to other information criteria?  AIC uses MAP estimates instead of the posterior and requires that priors be flat or overwhelmed by the likelihood, and assumes that the posterior distribution is approximately multivariate Gaussian and the sample size is  much greater  than the number of parameters used in the model. Bayesian Information Criterion (BIC) also requires flat priors and uses MAP estimates. WAIC does not make these assumptions, and provides almost exactly the same results as AIC, when AICâ€™s assumptions are met.}  applied to a wide selection of predictors lead to the model, whose specification is as follows (we also selected regularizing prior parameters using prior predictive checks to avoid unreasonably narrow overall prior distributions):


\vspace{-2mm}

\begin{align*}
\mathsf{AdiffS} & \sim \textsf{Norm}(\mu, \sigma)\\
\mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} + \beta_{\mathsf{group}_i}  +
 \beta_{\mathsf{IC}}[\mathsf{group}_i]\times \mathsf{IC} + \\
 & + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC} + \beta_{\mathsf{CBS}}[\mathsf{group}_i] \times \mathsf{CBS}\\
 \alpha & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{ADS}}[\mathsf{group}_i] & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{group}_i} & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{IC}}[\mathsf{group}_i] & \sim \textsf{Norm}(0,.3)\\
 \beta_{\mathsf{ADSIC}} & \sim \textsf{Norm}(0,.3)\\
 \beta_{\mathsf{CBS}}[\mathsf{group}_i]& \sim \textsf{Norm}(0,.3)\\
\end{align*}


That is, we take the resulting mean to be the result of the general average ($\alpha$) and the impact of the following coefficients: group-specific coefficient for \textsf{ADS}, group coefficient, group-specific coefficient for \textsf{IC}, interaction coefficient for \textsf{ADS} and \textsf{IC}, and group-specific coefficient for \textsf{CBS}. This is plausible \emph{prima facie} which group a user belongs to might have impact on  how attacks during the treatment is related to attacks after, the role  of the intervention count, and the role of comments before. Moreover, the levels of aggressive behavior displayed by the user during treatment might have impact on the role played by the intervention count. 

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=FALSE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
# building model with sd=1
InteractionsModelDiffSD1 <- ulam(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC+
    bADSIC * ADS * IC+ bCBS[groupID] *CBS,
    a ~ dnorm (0,1),
    bADS[groupID] ~ dnorm(0,1),
    bADSIC ~ dnorm(0,1),
    bCBS[groupID] ~ dnorm(0,1),
    bIT[groupID] ~ dnorm(0,1),
    bIC[groupID] ~ dnorm(0,1),
    sigma  ~ dexp(1)
  ),
  data = summaries
 )
 
#saveRDS(InteractionsModelDiffSD1, file = "models/InteractionsModelDiffSD1.rds")
InteractionsModelDiffSD1 <- readRDS(file = "models/InteractionsModelDiffSD1.rds")


#now model with prior sd = .3
InteractionsModelDiff <- ulam(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
    bADSIC * ADS * IC+ bCBS[groupID] *CBS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)

#saveRDS(InteractionsModelDiff, file = "models/InteractionsModelDiff.rds")

InteractionsModelDiff <- readRDS(file = "models/InteractionsModelDiff.rds")

#prior predictive checks sd =1
ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 5  #mean for interventions in treatment
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
prior <- extract.prior(InteractionsModelDiffSD1, n = 1e4)
mu <- link( InteractionsModelDiffSD1 , post=prior , data=data )
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")

priorGroupsSD1 <- ggplot(muLong)+
  geom_violin(aes(x = group, y = AdiffS))+
  theme_tufte()+xlab("")+
  labs(title = "Simulated priors by group",
  subtitle = "(at ADS = CBS = 0, IC at mean = 5, sd = 1)")+
  ylab("change in attacks (standardized)")

ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 0:20
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)

prior <- extract.prior(InteractionsModelDiffSD1, n = 1e4)
mu <- link(InteractionsModelDiffSD1 , post=prior , data=data )
mu.mean <- apply( mu , 2, mean )
mu.HPDI <- data.frame(t(apply( mu , 2 , HPDI )))
priorDF <- cbind(data, mu.mean, mu.HPDI)
priorDF$groupID <- as.factor(groupID)
levels(priorDF$groupID) <- c("control", "empathy", "normative")
colnames(priorDF)[2]<- "group"


priorICSD1  <- ggplot(priorDF, aes(x = IC, y  = mu.mean,  fill = group))+
  geom_line()+geom_ribbon(aes(ymin = X.0.89, ymax = X0.89.), alpha = 0.2)+
  theme_tufte()+ylab("change in attacks (standardized)")+
  labs(title = "Simulated priors for AAS vs IC",
      subtitle = "(at ADS = CBS = 0, sd = 1)")+xlab("interventions")


priorJoint1 <- ggarrange(priorGroupsSD1,priorICSD1, ncol = 2)
priorJoint1Titled <- annotate_figure(priorJoint1,
  top = text_grob("Predictive priors with sd=1 are insanely wide",
                  size = 14))
priorJoint1Titled

#Some experimentation leads to the value of $\sigma =.3$, which leads to the following priors:

prior predictive check sd =.3
ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 5  #mean for interventions in treatment
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
prior <- extract.prior(InteractionsModelDiff, n = 1e4)
mu <- link(InteractionsModelDiff , post=prior , data=data ) 
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")
head(muLong)

priorGroupSD03 <- ggplot(muLong)+
  geom_violin(aes(x = group, y = AdiffS))+theme_tufte()+
  xlab("")+
  labs(title = "Simulated priors  by group", 
  subtitle = "(at ADS = CBS = 0, IC at mean = 5, sd = .3)")+
  ylab("change in attacks (standarized)")

ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 5  #mean for interventions in treatment
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
prior <- extract.prior(InteractionsModelDiffSD1, n = 1e4)
mu <- link( InteractionsModelDiffSD1 , post=prior , data=data ) 
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")
head(muLong)

priorICSD03 <- ggplot(muLong)+
  geom_violin(aes(x = group, y = AdiffS))+
  theme_tufte()+xlab("")+
  labs(title = "Simulated priors by group", 
  subtitle = "(at ADS = CBS = 0, IC at mean = 5, sd = 1)")+
  ylab("change in attacks (standardized)")

priorJoint03 <- ggarrange(priorGroupSD03,priorICSD03, ncol = 2) 
priorJoint03Titled <- annotate_figure(priorJoint03, 
  top = text_grob("Predictive priors with sd=.3 seem sensible",
                  size = 14))
priorJoint03Titled
```
\normalsize





Now, some model diagnostics before we move on (Figure \ref{fig:traceplot}). What we are witnessing is (1) stationarity (the chains stay mostly in the most probable regions), (2) good mixing (they explore a range of options in the beginning), and (3) convergence (they stabilize as they progress).  We also need to   inspect the distribution of residuals, expecting them to be more or less normally distributed, which they are (Figure \ref{fig:residuals}).


\begin{figure}
```{r traceplot,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", results = "hide"}
InteractionsModelDiff <- readRDS(file = "models/InteractionsModelDiff.rds")
traceplot( InteractionsModelDiff )
```
\caption{Traceplot of the model selected using Widelly Acceptable Information Criterion.}
\label{fig:traceplot}
\end{figure}



\vspace{1mm}
\footnotesize
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", results = "hide"}
mu <- link(InteractionsModelDiff)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- summaries$AdiffS - mu_mean
ggplot()+geom_density(aes(x = mu_resid))+theme_tufte()+ theme(plot.title.position = "plot") +
  ggtitle("Residuals are approximately normally distributed")+xlab("residuals")
```
\caption{Distribution of residuals from the selected model.}
\label{fig:residuals}
\end{figure}







  
# Before-and-after analysis: results






<!-- \vspace{1mm} -->
<!-- \footnotesize -->
<!-- ```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"} -->
<!-- #head(summaries) %>% kable( "latex", booktabs = T) %>%  -->
<!-- #  kable_styling(latex_options = c("striped", "scale_down") ,font_size = 9) -->

<!-- ``` -->
<!-- \normalsize -->




















