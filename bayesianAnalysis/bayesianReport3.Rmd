---
title: "Bayesian analysis of the NESTA study of interventions against  verbal aggression online"
author: "Rafal Urbaniak"
output:
  pdf_document:
    number_sections: yes
    df_print: kable
    keep_tex: yes
    includes:
      in_header: Rafal_latex6.sty
  html_document:
    df_print: paged
  word_document: default
classoption: dvipsnames,enabledeprecatedfontcommands
fontsize: 10pt
documentclass: scrartcl
urlcolor: blue
bibliography: ../references/attacks.bib
csl: ../references/apa-6th-edition.csl
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = '../')

#libraries used
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(kableExtra)
library(viridis)
library(rethinking)
library(ggplot2)
library(ggpubr)
library(tidyverse)
library(GGally)
library(dagitty)
library(reshape)


mykable <- function(object) {kable(object, "latex", booktabs = T) %>% kable_styling(latex_options = "striped",font_size = 9)}  

removeX <-   theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

removeY <-   theme(axis.title.y=element_blank(),
                   axis.text.y=element_blank(),
                   axis.ticks.y=element_blank())

#kable(table(data$group), "latex", booktabs = T, col.names = c("Group", "n")) %>% 
#  kable_styling(latex_options = c("striped","HOLD_position"),font_size = 9) 
```



\tableofcontents


# Exploration

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
summaries <- read.csv(file = "datasets/Summaries.csv")
head(summaries) %>% kable( "latex", booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "scale_down") ,font_size = 9)
```
\normalsize

The basic variables we are dealing with are in the following table. 



```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
variable <- c("AB", "AD", "AA", "CB", "CD", "CA", "group", "IC")
explanation <- c("attacks before (pre-treatment)", "attacks during (the treatment period)",
                 "attacks after (post-treatment)", "comments before", "comments during",
                 "comments after", "treatment group", "intervention count")
vars <- data.frame(variable, explanation)
mykable(vars)
```



Further variables are defined in terms of those, in particular, we will be predicting \textsf{AdiffS} which is the standardized difference  \textsf{AA}-\textsf{AB}, and \textsf{AdiffS}, which is the standardized difference \textsf{CA}-\textsf{CB}. Before we proceed, we will also standardize the predictors, and add a numerical index for the group:

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
summaries$ABS <- standardize(summaries$AB)
summaries$CBS <- standardize(summaries$CB)
summaries$AAS <- standardize(summaries$AA)
summaries$CAS <- standardize(summaries$CA)
summaries$CDS <- standardize(summaries$CD)
summaries$ADS <- standardize(summaries$AD)
summaries$group <- as.factor(summaries$group)
summaries$groupID <-  as.integer( as.factor(summaries$group) )
```
\normalsize


First, let's take a look at the distribution of \textsf{IC} in the treatment groups:



\vspace{1mm}
\footnotesize
```{r treatmentHist,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
ggplot(summaries[summaries$group != "control",], aes(x = IC, fill = group))+
  geom_bar()+theme_tufte()+
  xlab("interventions received")+
  labs(title = "Intervention counts in treatment groups")+
  scale_x_continuous(breaks = seq(0,40,5))
```
\normalsize

\todo{Note there were much more empathetic interventions, this needs an explanation}

\todo{Question: intervention counts by group}

Second, when we look at the distribution of standardized difference in attacks, when restricted to (-1,1), the peaks of distributions are shifted a bit, with lowest median for the normative group, but not too much:

\vspace{1mm}
\footnotesize
```{r violEmpiricalAdiff,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
violAdiffS <- ggplot(summaries, aes(x=group, y = AdiffS))+
  geom_violin() +theme_tufte() 
violJoint <- ggarrange(violAdiffS+ggtitle("whole range"),
              violAdiffS + ylim(c(-1,1))+geom_boxplot(width = .2)+
              ggtitle("restricted to (-1,1)")) 
violJointTitled <- annotate_figure(violJoint, 
  top = text_grob("Empirical distribution of change in attacks (standardized)",
                  size = 12))
violJointTitled
```
\normalsize

Analogous plot for comments does not reveal this slight downward shift for normative, but otherwise the visualisation migth suggest no strong impact of interventions on attacks, and no impact on comments.




\vspace{1mm}
\footnotesize
```{r violEpmiricalCdiff,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
violCdiffS <- ggplot(summaries, aes(x=group, y = CdiffS))+
  geom_violin() +theme_tufte() 
violJointC <- ggarrange(violCdiffS+ggtitle("whole range"),
              violCdiffS + ylim(c(-1,1))+geom_boxplot(width = .2)+
              ggtitle("restricted to (-1,1)")) 
violJointCTitled <- annotate_figure(violJoint, 
  top = text_grob("Empirical distribution of change in comments (standardized)",
                  size = 12))
violJointCTitled
```
\normalsize




However, plotting changes against intervention counts reveals that restricting attention to various activity levels drastically changes the regression lines.

\vspace{1mm}
\footnotesize
```{r ic,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
icplot1 <- ggplot(summaries, aes(x = IC, y = AdiffS, color = group, fill = group))+
  geom_jitter(alpha = 0.6, size =.8)+theme_tufte()+
  geom_smooth(alpha = 0.2, method = "lm")+
  xlim(c(0,25))+ylim(c(-2,2))+
  ggtitle("sd restricted to (-2,2)")+
  theme(legend.position = c(0.65, 0.1))

icplot2 <-  ggplot(summaries, aes(x = IC, y = AdiffS, color = group, fill = group))+
  geom_jitter(alpha = 0.6, size =.8)+theme_tufte()+
  geom_smooth(alpha = 0.2, method = "lm")+
  xlim(c(0,25))+ylim(c(-1,1))+ggtitle("sd restricted to (-1,1)")+
  theme(legend.position = c(0.65, 0.1))

icplotJoint <- ggarrange(icplot1, icplot2) 
icplotTitled <- annotate_figure(icplotJoint, 
  top = text_grob("Change in attacks (standardized) vs interventions received",  size = 12))
icplotTitled
```
\normalsize

Some interactions are also suggested by the differences in linear smoothing when attention is restricted when it comes to change in comments.

\vspace{1mm}
\footnotesize
```{r icc,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
icCplot1 <- ggplot(summaries, aes(x = IC, y = CdiffS, color = group, fill = group))+
  geom_jitter(alpha = 0.6, size =.8)+theme_tufte()+
  geom_smooth(alpha = 0.2, method = "lm")+
  xlim(c(0,25))+ylim(c(-2,2))+
  ggtitle("sd restricted to (-2,2)")+
  theme(legend.position = c(0.65, 0.1))

icCplot2 <-  ggplot(summaries, aes(x = IC, y = CdiffS, color = group, fill = group))+
  geom_jitter(alpha = 0.6, size =.8)+theme_tufte()+
  geom_smooth(alpha = 0.2, method = "lm")+
  xlim(c(0,25))+ylim(c(-1,1))+ggtitle("sd restricted to (-1,1)")+
  theme(legend.position = c(0.65, 0.1))

icCplotJoint <- ggarrange(icCplot1, icCplot2) 
icCplotTitled <- annotate_figure(icCplotJoint, 
  top = text_grob("Change in comments (standardized) vs interventions received",
   size = 12))
icCplotTitled
```
\normalsize



This suggests we should keep an eye out for interactions in the analysis, and that the intial comparison of means or medians between groups might be misleading if the effects in different volume groups are different and cancel each other. 



Now, let's inspect correlations between the variables involved in the model:

\vspace{1mm}
\footnotesize
```{r correlations,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
summariesCorr <- select(summaries, IC, ABS, CBS, AAS, CAS, CDS, ADS)
ggcorr(summariesCorr, method = c("pairwise"),
       digits = 4, low = "steelblue", mid = "white",
       high = "darkred", midpoint =0,
       geom = "tile", label = TRUE, label_size=4, label_round =2, layout.exp =1,
       label_alpha = FALSE,hjust = 0.75)


```
\normalsize

This tells us that almost no predictors are strongly correlated, except for pairs \textsf{CBS}-\textsf{CDS}, so we drop CDS from the analysis and avoid using them  in the same model to avoid multicolinearity issues. These are just comments during the intervention period, which, unsurprisingly are also a good proxy for comments before and comments after.








# Causal inference 

To identify the right variables to condition (or not condition) on to identify the causal effect of the interventions, we first need to think about the causal structure of the problem. Here's a plausible causal structure that we will be working with:


\vspace{1mm}
\footnotesize
```{r dag1,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "80%"}
dag <- dagitty("
  dag{
  CDS -> ADS -> IC  
               U [unobserved]   
               U -> CBS -> ABS  
               U -> ABS        
               U -> CDS -> ADS  
               U -> ADS         
               U -> CAS -> AAS    
               U -> AAS                        
               IC -> AAS        
               IC -> CAS        
               IT -> CAS        
               IT -> AAS
               CBS -> CDS -> CAS
               ABS -> ADS -> AAS
               }")
coordinates(dag)
coordinates( dag ) <- list( x=c(CBS=0,ABS=0,CDS=1,ADS=1, CAS = 2,
                    AAS = 2, IT = 1.5, IC = 1.5, U = .5) ,
y=c(CBS =0,ABS = 1,CDS = 0,ADS = 1, CAS = 0, AAS = 1, 
    IT = .3, IC = .7, U =.5) )
drawdag(dag)
```
\normalsize

Comments during impact attacks during, which trigger interventions.
Unmeasured user features cause comments before, which impact attacks before, and also    attacks before directly. Comments during (their impact on ADS is areadly included)  impact attacks during during directly and  comments after, which impact attacks after and   attacks after directly.  Intervention count impacts attacks after  and comments after. The same directions of impact are included for intervention type. Finally, comments through time are connected causally, and so are attacks.

We already know not to condition on CDS if we condition on CAS or CBS. What else? \textsf{IT} has no bacwkard paths, but \textsf{IC} does. Let's identify all paths from \textsf{IC} to \textsf{AAS}:

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
paths(dag, from = c("IC"), to = "AAS")
```
\normalsize

Crucially, all backdoor paths go through \textsf{ADS}, which then becomes either a fork or a pipe, so all backdoor paths can be closed by conditioning on \textsf{ADS}. Moreover there is only one directed indirect path, it goes through \textsf{CAS}, so we should not condition on it if we are to identify causal effect on attacks mediated by impact on comments (unless we care about the direct effect of \textsf{IC}  and \textsf{IT} on \textsf{AAS}, but that's a separate question). This is in line with the adjustment set identified algorithmically.

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
adjustmentSets(dag, exposure = c("IC", "IT"), outcome = "AAS", type = "all")
```
\normalsize


The situation is different when it comes to evaluating the *direct* effect of intervention. Then, we also need to block indirect causal paths from the intervention to the outcome. For such an evaluation we need to also condition on \textsf{CAS}, which is what we will do when we turn to the study of the direct effects of the interventions. 


In fact, we will be predicting the difference between attacks before and after, and the difference between comments, before and after. Let's add them to the dag to double-check our selection of variables.

```{r dag2,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "80%"}
dag2 <- dagitty("
  dag{
                CDS -> ADS -> IC  
                U [unobserved]   
                U -> CBS -> ABS  
                U -> ABS        
                U -> CDS -> ADS  
                U -> ADS         
                U -> CAS -> AAS    
                U -> AAS                        
                IC -> AAS        
                IC -> CAS        
                IT -> CAS        
                IT -> AAS
                CBS -> CDS -> CAS
                ABS -> ADS -> AAS
                ABS -> AdiffS
                AAS -> AdiffS
                CBS -> CdiffS
                CAS -> CdiffS
                }")
coordinates( dag2 ) <- list( x=c(CBS=0,ABS=0,CDS=1,ADS=1,
    CAS = 2, AAS = 2, IT = 1.5, IC = 1.5, U = .5, AdiffS= 2.5, CdiffS = 2.5) ,
y=c(CBS =0,ABS = 1,CDS = 0,ADS = 1, CAS = 0, AAS = 1, IT = .3, IC = .7, U =.5, CdiffS = -.2,  AdiffS = 1.2) )

drawdag(dag2)
adjustmentSets(dag2, exposure = c("IC", "IT"), outcome = "AdiffS", type = "canonical")
```
 
Finding a maximal sensible set (canonical) of covariates suggests inlcuding \textsf{CDS} and \textsf{ABS}. As already discussed, we do not include \textsf{CDS} because of its strong correlation with \textsf{CBS}. We also do not condition on \textsf{ABS}---not only because it has a pretty strong correlation with another predictor (\textsf{ADS}), but rather mainly because it is used to define the output variable. In such a set-up, of course that a model including \textsf{ABS} would have better predictive power, but since a definitional connection is present, thinking that its inclusion in the model tells us something about causality  would be misled. 


It's open season for the  other variables (and interactions between them), and our decision to include them in the model will be guided by information-theoretic criteria of predictive power.  
  
  
  
  
  
  
  
  
  
  
  
  
  
We will focus on a class of additive models where the outcome variable is normally distributed around the predicted mean, which is a linear function of predictors (possibly with some interactions). To spoil the story, we will end up using a model, whose specification is as follows:

\begin{align*}
\mathsf{AdiffS} & \sim \textsf{Norm}(\mu, \sigma)\\
\mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} + \beta_{\mathsf{group}_i}  +
 \beta_{\mathsf{IC}}[\mathsf{group}_i]\times \mathsf{IC} + \\
 & + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC} + \beta_{\mathsf{CBS}}[\mathsf{group}_i] \times \mathsf{CBS}\\
 \alpha & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{ADS}}[\mathsf{group}_i] & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{group}_i} & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{IC}}[\mathsf{group}_i] & \sim \textsf{Norm}(0,.3)\\
 \beta_{\mathsf{ADSIC}} & \sim \textsf{Norm}(0,.3)\\
 \beta_{\mathsf{CBS}}[\mathsf{group}_i]& \sim \textsf{Norm}(0,.3)\\
\end{align*}

That is, we take the resulting mean to be the result of the general average ($\alpha$) and the impact of the following coefficients: group-specific coefficient for \textsf{ADS}, group coefficient, group-specific coefficient for \textsf{IC}, interaction coefficient for \textsf{ADS} and \textsf{IC}, and group-specific coeffient for \textsf{CBS}. This is plausible prima facie which group a user belongs to might have impact on  how attacks during the treatment is related to attacks after, the role  of the intervention count, and the role of comments before. Moreover, the levels of agressive behavior displayed by the user during treament might have impact on the role played by the intervention count. Later on we will see that there are information-theoretic reasons to include these interactions.



Now for the priors. One might be suspicious of $\sigma =.3$ we employed and suggest using standard normal distributions with $\sigma = 1$ instead. However, a quick prior predictive check shows that this results in insanely wide priors that are competely unrealistic. (For computational reasons, instead of running the simulations, we load pre-compiled models, but we include the code used to build them).


\vspace{1mm}
\footnotesize
```{r priors1,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", results= "hide"}
# building model with sd=1
# InteractionsModelDiffSD1 <- ulam(
#   alist(
#     AdiffS ~ dnorm( mu, sigma ),
#     mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC+
#     bADSIC * ADS * IC+ bCBS[groupID] *CBS,
#     a ~ dnorm (0,1),
#     bADS[groupID] ~ dnorm(0,1),
#     bADSIC ~ dnorm(0,1),
#     bCBS[groupID] ~ dnorm(0,1),
#     bIT[groupID] ~ dnorm(0,1),
#     bIC[groupID] ~ dnorm(0,1),
#     sigma  ~ dexp(1)
#   ), 
#   data = summaries
# )
# 
# saveRDS(InteractionsModelDiffSD1, file = "models/InteractionsModelDiffSD1.rds")
InteractionsModelDiffSD1 <- readRDS(file = "models/InteractionsModelDiffSD1.rds")


#now model with prior sd = .3
# InteractionsModelDiff <- ulam(
#   alist(
#     AdiffS ~ dnorm( mu, sigma ),
#     mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
#     bADSIC * ADS * IC+ bCBS[groupID] *CBS,
#     a ~ dnorm (0,0.3),
#     bADS[groupID] ~ dnorm(0,.3),
#     bADSIC ~ dnorm(0,.3),
#     bCBS[groupID] ~ dnorm(0,.3),
#     bIT[groupID] ~ dnorm(0,.3),
#     bIC[groupID] ~ dnorm(0,.3),
#     sigma  ~ dexp(1)
#   ), 
#   data = summaries
# )

#saveRDS(InteractionsModelDiff, file = "models/InteractionsModelDiff.rds")

InteractionsModelDiff <- readRDS(file = "models/InteractionsModelDiff.rds")

##prior predictive checks sd =1
ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 5  #mean for interventions in treatment
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
prior <- extract.prior(InteractionsModelDiffSD1, n = 1e4)
mu <- link( InteractionsModelDiffSD1 , post=prior , data=data ) 
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")

priorGroupsSD1 <- ggplot(muLong)+
  geom_violin(aes(x = group, y = AdiffS))+
  theme_tufte()+xlab("")+
  labs(title = "Simulated priors by group",
  subtitle = "(at ADS = CBS = 0, IC at mean = 5, sd = 1)")+
  ylab("change in attacks (standardized)")

ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 0:20
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)

prior <- extract.prior(InteractionsModelDiffSD1, n = 1e4)
mu <- link(InteractionsModelDiffSD1 , post=prior , data=data ) 
mu.mean <- apply( mu , 2, mean )
mu.HPDI <- data.frame(t(apply( mu , 2 , HPDI )))
priorDF <- cbind(data, mu.mean, mu.HPDI)
priorDF$groupID <- as.factor(groupID)
levels(priorDF$groupID) <- c("control", "empathy", "normative")
colnames(priorDF)[2]<- "group"


priorICSD1  <- ggplot(priorDF, aes(x = IC, y  = mu.mean,  fill = group))+
  geom_line()+geom_ribbon(aes(ymin = X.0.89, ymax = X0.89.), alpha = 0.2)+
  theme_tufte()+ylab("change in attacks (standardized)")+
  labs(title = "Simulated priors for AAS vs IC",
      subtitle = "(at ADS = CBS = 0, sd = 1)")+xlab("interventions")


priorJoint1 <- ggarrange(priorGroupsSD1,priorICSD1, ncol = 2) 
priorJoint1Titled <- annotate_figure(priorJoint1, 
  top = text_grob("Predictive priors with sd=1 are insanely wide",
                  size = 14))
priorJoint1Titled
```
\normalsize



Some experimentation leads to the value of $\sigma =.3$, which leads to the following priors:

\vspace{1mm}
\footnotesize
```{r priors03,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", results= "hide"}
#prior predictive check sd =.3
ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 5  #mean for interventions in treatment
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
prior <- extract.prior(InteractionsModelDiff, n = 1e4)
mu <- link(InteractionsModelDiff , post=prior , data=data ) 
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")
head(muLong)

priorGroupSD03 <- ggplot(muLong)+
  geom_violin(aes(x = group, y = AdiffS))+theme_tufte()+
  xlab("")+
  labs(title = "Simulated priors  by group", 
  subtitle = "(at ADS = CBS = 0, IC at mean = 5, sd = .3)")+
  ylab("change in attacks (standarized)")

ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 5  #mean for interventions in treatment
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
prior <- extract.prior(InteractionsModelDiffSD1, n = 1e4)
mu <- link( InteractionsModelDiffSD1 , post=prior , data=data ) 
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")
head(muLong)

priorICSD03 <- ggplot(muLong)+
  geom_violin(aes(x = group, y = AdiffS))+
  theme_tufte()+xlab("")+
  labs(title = "Simulated priors by group", 
  subtitle = "(at ADS = CBS = 0, IC at mean = 5, sd = 1)")+
  ylab("change in attacks (standardized)")

priorJoint03 <- ggarrange(priorGroupSD03,priorICSD03, ncol = 2) 
priorJoint03Titled <- annotate_figure(priorJoint03, 
  top = text_grob("Predictive priors with sd=.3 seem sensible",
                  size = 14))
priorJoint03Titled
```
\normalsize





Now, some model diagnostics before we move on. What we are witnessing is (1) stationarity (the chains stay mostly in the most probable regions), (2) good mixing (they explore a range of options in the beginning), and (3) convergence (they stabilize as they progress).  

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", results = "hide"}
traceplot( InteractionsModelDiff )
```
\normalsize


Finally, let's inspect the distribution of residuals. That is, we calculate all predictions, their distance from the actual values, and inspect the distribution of the distances:

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", results = "hide"}
mu <- link(InteractionsModelDiff)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- summaries$AdiffS - mu_mean
ggplot()+geom_density(aes(x = mu_resid))+theme_tufte()+
  ggtitle("Residuals are approximately normally distributed")+xlab("residuals")
```
\normalsize



# Model selection


How did we get to this fairly complicated model though? Once preliminary causal considerations guided our restrictions on variable selection, we proceed by building models of increasing complexity, and comparing them in terms of Widely Acceptable Information Criterion. The models differ mostly in the underlying linear formulae. For computational ease we will here use quadratic approximations, while in the final analysis we will deploy Hamiltionian Monte Carlo. The names are meant to decode the model structure: the predictors are listed before dashes, whereas interactions are listed after dashes.

\begin{align}
\tag{Null}  \mu_i & = \alpha\\
\tag{ADS}  \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS}\\
\tag{ADSIC}  \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS} +    \beta_{\mathsf{IC}}\times \mathsf{IC}\\
\tag{IT}  \mu_i & = \beta_{\mathsf{group}[i]} \\
\tag{ADSIT} \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS} +  \beta_{\mathsf{group}[i]}\\
\tag{ADSITIC} \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS} +  \beta_{\mathsf{group}[i]} +    \beta_{\mathsf{IC}}\times \mathsf{IC}\\
\tag{ADSITIC-ADSIC} \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS} +  \beta_{\mathsf{group}[i]} +    \beta_{\mathsf{IC}}\times \mathsf{IC} + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC}\\
\tag{ADSITIC-ADSIC-ADSIT} \mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} +  \beta_{\mathsf{group}[i]} +  \\ \nonumber & +  \beta_{\mathsf{IC}}\times \mathsf{IC} + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC}\\
\tag{ADSIT-ADSIT}   \mu_i &  = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i] \times
 \mathsf{ADS} + \beta_{\mathsf{group}[i]} \\
\tag{ADSITIC-ADSIT-ITIC-ADSIC}   \mu_i &  = \alpha  +  \beta_{\mathsf{ADS}}[\mathsf{group}_i] \times \mathsf{ADS} + \beta_{\mathsf{group}[i]} +  
\beta_{\mathsf{IC}}[\mathsf{group}_i] \times \mathsf{IC} + \\ \nonumber & + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC}\\
\tag{ADSITICCBS-ITIC-ADSIC} \mu_i &  = \alpha  +  \beta_{\mathsf{ADS}}[\mathsf{group}_i] \times
 \mathsf{ADS}  + \beta_{\mathsf{group}[i]} +   \beta_{\mathsf{IC}}[\mathsf{group}_i] \times \mathsf{IC} + \\ & \nonumber  + \beta_{\mathsf{CBS}} \times \mathsf{CBS} +  \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC}  \\
\tag{Final} \mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} + \beta_{\mathsf{group}_i}  +  \beta_{\mathsf{IC}}[\mathsf{group}_i]\times \mathsf{IC} + \\
 & + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC} + \beta_{\mathsf{CBS}}[\mathsf{group}_i] \times \mathsf{CBS} \nonumber\\
 \tag{tooFAr} \mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} + \beta_{\mathsf{group}_i}  +  \beta_{\mathsf{IC}}[\mathsf{group}_i]\times \mathsf{IC} + \\
 & + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC} + \beta_{\mathsf{CBS}}[\mathsf{group}_i] \times \mathsf{CBS} + \beta_{\mathsf{CBSIC}}\times
 \mathsf{CBS} \times \mathsf{IC}\end{align}








\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
null <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu ~ dnorm (0,0.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries  
)

ADS <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  a + bADS * ADS,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)

ADSIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  a + bADS * ADS+ bIC * IC,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,0.3),
    bIC ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


IT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  bIT[groupID] ,
    bIT[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSIT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID],
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID] + bIC * IC,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITIC_ADSIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID] + bIC * IC + bADSIC * ADS * IC,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITIC_ADSIC_ADSIT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC * IC + bADSIC * ADS * IC,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSIT_ADSIT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] ,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    #bADSIC ~ dnorm(0,.5),
    bIT[groupID] ~ dnorm(0,.3),
    #bIC ~ dnorm(0,.5),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITIC_ADSIT_ITIC_ADSIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
      bADSIC * ADS * IC,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITICCBS_ITIC_ADSIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS *CBS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


Final <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS[groupID] *CBS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)



tooFar <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS[groupID] *CBS + bCBSIC * CBS * IC, 
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
     bCBSIC ~ dnorm(0, .3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)

```
\normalsize



\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
comparison<- compare(null,ADS,ADSIC,IT,ADSIT,ADSITIC,ADSITIC_ADSIC,
                     ADSITIC_ADSIC_ADSIT,ADSIT_ADSIT,ADSITIC_ADSIT_ITIC_ADSIC,
                     ADSITICCBS_ITIC_ADSIC,Final, tooFar)
mykable(round(data.frame(comparison ),3)) 
plot(comparison)
```
\normalsize

The three models that stand out  differ in including $\mathsf{CBS}$ as a predictor.  Moreover the final model includes an interaction between  treatment group and $\mathsf{CBS}$. Adding a further interaction between $\mathsf{CBS}$ and $\mathsf{IC}$ takes us too far.  $WAIC$-based weighing assigns the weight of $83\%$ to the final model, and the standard errors for the difference in WAIC for the top three models is fairly low,  so we will employ the top model ($\mathsf{Final}$) in   further analyses. 


# Inspecting the model and effect sizes



We start by using the \textsf{Final} model formula to build a model, this time using Hamiltionian Monte Carlo. We leave the code commented out and load a pre-compiled model for computational convenience

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
# FinalHMC <- ulam(
#   alist(
#     AdiffS ~ dnorm( mu, sigma ),
#     mu <- a + bADS[groupID] * ADS +  bIT[groupID] +
#     bIC[groupID] * IC + bADSIC * ADS * IC+
#     bCBS[groupID] *CBS,
#     a ~ dnorm (0,0.3),
#     bADS[groupID] ~ dnorm(0,.3),
#     bADSIC ~ dnorm(0,.3),
#     bCBS[groupID] ~ dnorm(0,.3),
#     bIT[groupID] ~ dnorm(0,.3),
#     bIC[groupID] ~ dnorm(0,.3),
#     sigma  ~ dexp(1)
#   ),
#   data = summaries
# )
# saveRDS(FinalHMC, file = "models/FinalHMC.rds")


#saveRDS(FinalHMC, file = "models/FinalHMC.rds")

FinalHMC <- readRDS(file = "models/FinalHMC.rds")
```
\normalsize
First, let's take a look at the best model coefficients.

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
mykable(data.frame(precis(FinalHMC, depth = 2)))
plot(precis(FinalHMC, depth = 2))
```
\normalsize


These, however, are notoriously hard to interpret in models with interactions. For this reason, it is better to plot predicted effects for various combinations of predictors. 

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}

visGroup <- function (model, ADS, CBS, xmin =2, ymax = -3)
{
groupID <- 1:3
IC <- 5 
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
posterior <- extract.samples(model, n = 1e5)
mu <- link( model, data=data ) 
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")
means <-  round(apply(mu , 2 , mean ), 2)
mu_HPDI <- round(apply( mu , 2 , HPDI ),2)
means <- as.data.frame(means)
means$group <- rownames(means)
rownames(means) <- NULL
meansDisp <- cbind(means,t(as.data.frame(mu_HPDI)))
meansDisp <- meansDisp[,c(1,3,4)]

plot <- ggplot(muLong)+geom_violin(aes(x = group, y = AdiffS), alpha = 0.2)+
  xlab("")+
  labs(title = paste("ADS=", ADS, ", CBS=",  CBS,  sep = ""))+
  theme_tufte()+ylim(c(-4,4))
#+   annotation_custom(tableGrob(meansDisp), xmin=xmin,  ymax=ymax)
return(plot)
}


visGroupA2C_2 <- visGroup(model = FinalHMC, ADS = 2,CBS = -2)
visGroupA2C0 <- visGroup(model = FinalHMC, ADS = 2,CBS = 0 )
visGroupA2C2 <- visGroup(model = FinalHMC, ADS = 2,CBS = 2)

visGroupA0C_2 <- visGroup(model = FinalHMC, ADS = 0,CBS = -2 )
visGroupA0C0 <- visGroup(model = FinalHMC, ADS = 0,CBS = 0 )
visGroupA0C2 <-  visGroup(model = FinalHMC, ADS = 0,CBS = 2)

visGroupA2C_2 <-  visGroup(model = FinalHMC, ADS = 2,CBS = -2 )
visGroupA2C0 <- visGroup(model = FinalHMC, ADS = 2,CBS = 0 )
visGroupA2C2 <- visGroup(model = FinalHMC, ADS = 2,CBS = 2 )

visGroupJoint <- ggarrange(visGroupA2C_2+removeX + ggtitle("CBS = -2")+ylab("ADS = 2") , visGroupA2C0+theme_void()+ ggtitle("CBS = 0"),visGroupA2C2+theme_void()+ ggtitle("CBS = 2"), 
          visGroupA0C_2+removeX+ylab("ADS = 0")+ggtitle(""), visGroupA0C0+theme_void()+ggtitle(""), visGroupA0C2+theme_void()+ggtitle(""),
          visGroupA2C_2+ylab("ADS = -2")+ggtitle(""), visGroupA2C0+removeY+ggtitle(""), visGroupA2C2+removeY+ggtitle(""), ncol =3, nrow = 3)

 
visGroupJoint2 <- annotate_figure(visGroupJoint, 
  top = text_grob("(range restricted to (-4,4), IC at the rounded mean = 5)",
                  size = 10))
visGroupJoint3 <- annotate_figure(visGroupJoint2, 
  top = text_grob("Predicted change in attacks by activity type and treatment groups (standardized)",
                  size = 12))

visGroupJoint3 
```
\normalsize





To gain more clarity, let's look at predicted contrasts, here understood as distances from the control group mean, by activity types, first versus CBS, then versus ADS.



\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", message = FALSE, warning = FALSE}
visContrastsCBS <- function(model = FinalHMC, ADS = ADS , IC =  5,
                            CBS = seq(-3,3,by  = 0.1))
  {
  groupID <- 1:3
  data <- expand.grid(ADS, groupID, IC , CBS)
  colnames(data) <- c("ADS", "groupID", "IC", "CBS")
  posterior <- extract.samples(model, n = 1e5)
  link( model, data=data ) 
  mu <- link( model, data=data ) 
  means <-  round(apply(mu , 2 , mean ), 4)
  HPDIs <- round(apply( mu , 2 , HPDI ),4)
  visContrast <- cbind(data,means,t(as.data.frame(HPDIs)))
  
  ones <- 3 * (1:(nrow(visContrast)/3))-2
  twos <- 3 * (1:(nrow(visContrast)/3))-1
  threes <- 3 * (1:(nrow(visContrast)/3))
  
  colnames(visContrast)[c(6,7)] <- c("low", "high")
  contrast <- numeric(nrow(visContrast))
  cLow <- numeric(nrow(visContrast))
  cHigh <- numeric(nrow(visContrast))
  for(i in threes){
  contrast[i] <- visContrast$means[i] - visContrast$means[i-2]  
  }
  for(i in twos){
  contrast[i] <- visContrast$means[i] - visContrast$means[i-1]  
  }
  visContrast$contrast <- contrast
  visContrast$shift <-  visContrast$contrast - visContrast$means
  for(i in ones){
  visContrast$shift[i] <- 0
  }
  visContrast$cLow <- visContrast$low + visContrast$shift
  visContrast$cHigh <- visContrast$high + visContrast$shift

  visContrast$group = rep(c("control", "empathy", "normative"), 
                          nrow(visContrast)/3)

  visContrastTreatment <- visContrast[groupID !=1,]

  return(ggplot(visContrastTreatment, aes(x = CBS, y = contrast, fill = group ))+
           geom_line(se = FALSE)+
            geom_ribbon(mapping = 
        aes(ymin = cLow, ymax = cHigh),  
         alpha = .3)+
          theme_tufte())
}


visContrastCBSJoint <- ggarrange(visContrastsCBS(FinalHMC,ADS = -2)+
      ggtitle("ADS = -2")+ylim(c(-2.5,2.5))+ scale_fill_discrete(guide=FALSE),
          visContrastsCBS(FinalHMC,ADS = 0)+ggtitle("ADS = 0")+
        ylim(c(-2.5,2.5))+ scale_fill_discrete(guide=FALSE)+
        removeY,
        visContrastsCBS(FinalHMC,ADS = 2)+ggtitle("ADS = 2")+
        ylim(c(-2.5,2.5))+ theme(legend.position = c(0.75, 0.15))+
        removeY, ncol = 3)

visContrastCBSJoint2 <- annotate_figure(visContrastCBSJoint, 
      top = text_grob("(range restricted to (-2.5,2.5), IC at the rounded mean = 5)",
                                size = 10))
visContrastCBSJoint3 <- annotate_figure(visContrastCBSJoint2, 
top = text_grob("Predicted distance from the control group mean vs. CBS  (standardized)",
                                size = 12))

visContrastCBSJoint3
```
\normalsize


\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold",out.width = "100%", warning = FALSE, message = FALSE}

visContrastsADS <- function(model = FinalHMC, CBS = CBS , IC =  5, 
                            ADS = seq(-3,3,by  = 0.1))
{
  data <- expand.grid(CBS, groupID, IC , ADS)
  colnames(data) <- c("CBS", "groupID", "IC", "ADS")
  posterior <- extract.samples(model, n = 1e5)
  mu <- link( model, data=data ) 
  means <-  round(apply(mu , 2 , mean ), 4)
  HPDIs <- round(apply( mu , 2 , HPDI ),4)
  visContrastADS <- cbind(data,means,t(as.data.frame(HPDIs)))


  ones <- 3 * (1:(nrow(visContrastADS)/3))-2
  twos <- 3 * (1:(nrow(visContrastADS)/3))-1
  threes <- 3 * (1:(nrow(visContrastADS)/3))
  
  colnames(visContrastADS)[c(6,7)] <- c("low", "high")
  contrastADS <- numeric(nrow(visContrastADS))
  for(i in threes){
    contrastADS[i] <- visContrastADS$means[i] - visContrastADS$means[i-2]  
  }
  for(i in twos){
    contrastADS[i] <- visContrastADS$means[i] - visContrastADS$means[i-1]  
  }
  visContrastADS$contrast <- contrastADS
  visContrastADS$shift <-  visContrastADS$contrast - visContrastADS$means
  for(i in ones){
    visContrastADS$shift[i] <- 0
  }
  visContrastADS$cLow <- visContrastADS$low + visContrastADS$shift
  visContrastADS$cHigh <- visContrastADS$high + visContrastADS$shift
  
  visContrastADS$group = rep(c("control", "empathy", "normative"), 
                             nrow(visContrastADS)/3)
  visContrastTreatmentADS <- visContrastADS[groupID !=1,]

  return(ggplot(visContrastTreatmentADS, aes(x = ADS, y = contrast, fill = group ))+
           geom_line(se = FALSE) +
  geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), 
       alpha = .3) +theme_tufte())
}



visContrastADSJoint <- ggarrange(visContrastsADS(FinalHMC,CBS = -2)+ggtitle("CBS = -2")
                                 +ylim(c(-2.5,2.5))+ scale_fill_discrete(guide=FALSE),
                                 visContrastsADS(FinalHMC,CBS = 0)+ggtitle("CBS = 0")
                                 +ylim(c(-2.5,2.5))+ scale_fill_discrete(guide=FALSE)+
                                   removeY,
                                 visContrastsADS(FinalHMC,CBS = 2)+ggtitle("CBS = 2")
                                 +ylim(c(-2.5,2.5))+
                                   theme(legend.position = c(0.75, 0.15))+
                                   removeY, ncol = 3)

visContrastADSJoint2 <- annotate_figure(visContrastADSJoint, 
top = text_grob("(range restricted to (-2.5,2.5), IC at the rounded mean = 5)",
                                                        size = 10))
visContrastADSJoint3 <- annotate_figure(visContrastADSJoint2, 
top = text_grob("Predicted distance from the control group mean vs. ADS (standardized)",
                                                        size = 12))

visContrastADSJoint3
```
\normalsize


Now, let's inspect the impact of intervention counts by treatment type by looking at contrasts (distances from the control group mean) with 89% HPDIs by IC. Notice the predicted effect of \textsf{IC} is weaker than group membership, so for visibility the $y$-axis has a smaller range. Also, not enough data was available to reliably estimate uncertainty for \textsf{IC} above 20, hence the restriction on the $x$-axis (arleady at lower values, lack of estimates is visible for the more extreme  covariate settings).




\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
visContrastsIC <- function(model = FinalHMC, CBS = CBS ,
                           IC =  seq(0,20,by = 1), ADS = ADS)
{
  groupID <- 1:3
  data <- expand.grid(CBS, groupID, IC , ADS)
  data
  colnames(data) <- c("CBS", "groupID", "IC", "ADS")
  posterior <- extract.samples(model, n = 1e5)
  mu <- link( model, data=data ) 
  means <-  round(apply(mu , 2 , mean ), 4)
  HPDIs <- round(apply( mu , 2 , HPDI ),4)
  visContrastIC <- cbind(data,means,t(as.data.frame(HPDIs)))
  
  ones <- 3 * (1:(nrow(visContrastIC)/3))-2
  twos <- 3 * (1:(nrow(visContrastIC)/3))-1
  threes <- 3 * (1:(nrow(visContrastIC)/3))
  
  colnames(visContrastIC)[c(6,7)] <- c("low", "high")
  contrastIC <- numeric(nrow(visContrastIC))
  for(i in threes){
    contrastIC[i] <- visContrastIC$means[i] - visContrastIC$means[i-2]  
  }
  for(i in twos){
    contrastIC[i] <- visContrastIC$means[i] - visContrastIC$means[i-1]  
  }
  visContrastIC$contrast <- contrastIC
  visContrastIC$shift <-  visContrastIC$contrast - visContrastIC$means
  for(i in ones){
    visContrastIC$shift[i] <- 0
  }
  visContrastIC$cLow <- visContrastIC$low + visContrastIC$shift
  visContrastIC$cHigh <- visContrastIC$high + visContrastIC$shift
  
  visContrastIC$group = rep(c("control", "empathy", "normative"),
                            nrow(visContrastIC)/3)
  visContrastTreatmentIC <- visContrastIC[groupID !=1,]
  
  return(ggplot(visContrastTreatmentIC, aes(x = IC, y = contrast, fill = group ))+
           geom_line(se=FALSE)+
    geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), alpha = .3)+
    ylim(c(-2,2)) +theme_tufte()+geom_hline(yintercept = 0, lty =2, size = 0.1))
}


visContrastsICJoint <- ggarrange(
visContrastsIC(ADS = 2, CBS = -2)+removeX+ 
               theme(legend.position = c(0.3, 0.9),
                     legend.key.size = unit(.3, 'cm'),
                     legend.key.height = unit(.3, 'cm'),
                     legend.key.width = unit(.3, 'cm'),
                     legend.title= element_blank())+
  ggtitle("CBS = -2")+
  ylab("ADS = 2"),
    visContrastsIC(ADS = 2, CBS = 0)+removeY+removeX+ scale_fill_discrete(guide=FALSE)+
  ggtitle("CBS = 0"),
    visContrastsIC(ADS = 2, CBS = 2)+removeY+removeX+ggtitle("CBS = 2")+ scale_fill_discrete(guide=FALSE),
visContrastsIC(ADS = 0, CBS = -2)+removeX+ scale_fill_discrete(guide=FALSE)+
  ylab("ADS = 0"),
    visContrastsIC(ADS = 0, CBS = 0)+removeY+removeX+ 
  scale_fill_discrete(guide=FALSE),
    visContrastsIC(ADS = 0, CBS = 2)+removeY+removeX+ scale_fill_discrete(guide=FALSE),  
visContrastsIC(ADS = -2, CBS = -2)+ scale_fill_discrete(guide=FALSE)+
  ylab("ADS = -2"),
    visContrastsIC(ADS = -2, CBS = 0)+removeY+ scale_fill_discrete(guide=FALSE),
    visContrastsIC(ADS = -2, CBS = 0)+removeY+ scale_fill_discrete(guide=FALSE), 
ncol = 3, nrow = 3
)

visContrastsICJoint2 <- annotate_figure(visContrastsICJoint, 
top = text_grob("(range restricted to (-3,3))", 
                size = 10))
visContrastsICJoint3 <- annotate_figure(visContrastsICJoint2, 
 top = text_grob("Predicted distance from the control group mean vs. IC (standardized)",
                size = 12))

visContrastsICJoint3
```
\normalsize


# Direct effect


Models for the evaluation of direct effect need to close the indirect causal path from the treatment variables to the output, and they do so by conditioning on \textsf{CAS}. Again, we face model selection. We repeat all the model structures from the previous section, except for now, each model is extended with \textsf{CAS} as a predictor. This time the model structure we called \textsf{tooFar} turns out to do better. We also consider extending it with interactions between \textsf{CAS} and \textsf{IT} and \textsf{IC} (jointly and separately), but this results in no further improvement.


\vspace{1mm}
\footnotesize
```{r comparisonDirectModels,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
nullDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bCAS * CAS,
    a ~ dnorm (0,0.3),
    bCAS ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries  
)

ADSDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  a + bADS * ADS+ bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,0.3),
    bCAS ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)

ADSICDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  a + bADS * ADS+ bIC * IC+ bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,0.3),
    bIC ~ dnorm(0,0.3),
    bCAS ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)

ITDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  bIT[groupID] + bCAS * CAS,
    bIT[groupID] ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)

ADSITDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID]+ bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bIT[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITICDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID] + bIC * IC+ bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITIC_ADSICDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID] + bIC * IC + bADSIC * ADS * IC+ bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bADSIC ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITIC_ADSIC_ADSITDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC * IC + bADSIC * ADS * IC+ bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSIT_ADSITDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    #bADSIC ~ dnorm(0,.5),
    bIT[groupID] ~ dnorm(0,.3),
    #bIC ~ dnorm(0,.5),
    bCAS ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITIC_ADSIT_ITIC_ADSICDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
      bADSIC * ADS * IC + bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


ADSITICCBS_ITIC_ADSICDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS *CBS + bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


FinalDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS[groupID] *CBS + bCAS * CAS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)



tooFarDirect <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS[groupID] *CBS + bCBSIC * CBS * IC + bCAS * CAS, 
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    bCBSIC ~ dnorm(0, .3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)




tooFarDirect_CASIT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS[groupID] *CBS + bCBSIC * CBS * IC + bCAS[groupID] * CAS, 
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCAS[groupID] ~ dnorm(0,0.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    bCBSIC ~ dnorm(0, .3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)



tooFarDirect_CASIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS[groupID] *CBS + bCBSIC * CBS * IC + bCAS * CAS + bCASIC * CAS * IC, 
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCAS ~ dnorm(0,0.3),
    bCASIC ~ dnorm(0,0.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    bCBSIC ~ dnorm(0, .3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)


tooFarDirect_CASIC_CASIT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
      bADSIC * ADS * IC+ bCBS[groupID] *CBS + bCBSIC * CBS * IC + bCAS[groupID] * CAS + bCASIC * CAS * IC, 
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCAS[groupID] ~ dnorm(0,0.3),
    bCASIC ~ dnorm(0,0.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    bCBSIC ~ dnorm(0, .3),
    sigma  ~ dexp(1)
  ), 
  data = summaries
)








comparisonDirect<- compare(nullDirect,ADSDirect,ADSICDirect,ITDirect,ADSITDirect,ADSITICDirect,ADSITIC_ADSICDirect, ADSITIC_ADSIC_ADSITDirect,ADSIT_ADSITDirect,ADSITIC_ADSIT_ITIC_ADSICDirect,
                     ADSITICCBS_ITIC_ADSICDirect,FinalDirect, tooFarDirect,tooFarDirect_CASIT,
                     tooFarDirect_CASIC,tooFarDirect_CASIC_CASIT)


mykable(round(data.frame(comparisonDirect),3))%>% kable_styling(latex_options = c("striped","scale_down"),font_size = 9)  



plot(comparisonDirect)

```
\normalsize


Let's build a Hamiltonian Monte Carlo with the same formula:

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}

# tooFarDirectHMC <- ulam(
#   alist(
#     AdiffS ~ dnorm( mu, sigma ),
#     mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC + 
#       bADSIC * ADS * IC+ bCBS[groupID] *CBS + bCBSIC * CBS * IC + bCAS * CAS, 
#     a ~ dnorm (0,0.3),
#     bADS[groupID] ~ dnorm(0,.3),
#     bADSIC ~ dnorm(0,.3),
#     bCAS ~ dnorm(0,0.3),
#     bCBS[groupID] ~ dnorm(0,.3),
#     bIT[groupID] ~ dnorm(0,.3),
#     bIC[groupID] ~ dnorm(0,.3),
#     bCBSIC ~ dnorm(0, .3),
#     sigma  ~ dexp(1)
#   ), 
#   data = summaries
# )


#saveRDS(tooFarDirectHMC, file = "models/tooFarDirectHMC.rds")

tooFarDirectHMC <- readRDS(file = "models/tooFarDirectHMC.rds")
```
\normalsize

For a big picture, let's look at predicted direct effect by group and user activity profile.


\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}


visGroupDirect <- function (model, ADS, CBS, CAS, xmin =2, ymax = -3)
{
  groupID <- 1:3
  IC <- 5 
  data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, CAS = CAS, IC =  IC)
  posterior <- extract.samples(model, n = 1e5)
  mu <- link( model, data=data ) 
  colnames(mu) <- levels(summaries$group)
  muLong <- melt(mu)
  colnames(muLong) <- c("id", "group", "AdiffS")
  means <-  round(apply(mu , 2 , mean ), 2)
  mu_HPDI <- round(apply( mu , 2 , HPDI ),2)
  means <- as.data.frame(means)
  means$group <- rownames(means)
  rownames(means) <- NULL
  meansDisp <- cbind(means,t(as.data.frame(mu_HPDI)))
  meansDisp <- meansDisp[,c(1,3,4)]
  
  plot <- ggplot(muLong)+geom_violin(aes(x = group, y = AdiffS), alpha = 0.2)+
    xlab("")+
    labs(title = paste("ADS=", ADS, ", CBS=",  CBS, ", CAS=", CAS,  sep = ""))+
    theme_tufte()+ylim(c(-4,4))
  #+   annotation_custom(tableGrob(meansDisp), xmin=xmin,  ymax=ymax)
  return(plot)
}



visGroupDirect2_2_2 <-  visGroupDirect(model = tooFarDirectHMC, ADS = 2,CBS = -2, CAS = -2)
visGroupDirect200 <-  visGroupDirect(model = tooFarDirectHMC, ADS = 2,CBS = 0, CAS = 0)
visGroupDirect222 <- visGroupDirect(model = tooFarDirectHMC, ADS = 2,CBS = 2, CAS = 2)

visGroupDirect0_2_2 <-  visGroupDirect(model = tooFarDirectHMC, ADS = 0,CBS = -2, CAS = -2)
visGroupDirect000 <-  visGroupDirect(model = tooFarDirectHMC, ADS = 0,CBS = 0, CAS = 0)
visGroupDirect022 <- visGroupDirect(model = tooFarDirectHMC, ADS = 0,CBS = 2, CAS = 2)


visGroupDirect_2_2_2 <-  visGroupDirect(model = tooFarDirectHMC, ADS = -2,CBS = -2, CAS = -2)
visGroupDirect_200 <-  visGroupDirect(model = tooFarDirectHMC, ADS = -2,CBS = 0, CAS = 0)
visGroupDirect_222 <- visGroupDirect(model = tooFarDirectHMC, ADS = -2,CBS = 2, CAS = 2)


visGroupDirectJoint <- ggarrange(visGroupDirect2_2_2+removeX +ylab("ADS = 2")+ggtitle("CBS = CAS = -2"),
                                 visGroupDirect200+removeX+removeY+ ggtitle("CBS = CAS = 0"),
                                 visGroupDirect222+removeX+removeY+ ggtitle("CBS = CAS = 2") ,
                        visGroupDirect0_2_2+removeX + ggtitle("")+ylab("ADS = 0"),
                                visGroupDirect000+removeX+removeY+ ggtitle(""),
                                visGroupDirect022+removeX+removeY+ ggtitle(""),
                        visGroupDirect_2_2_2+removeX+ylab("ADS = -2")+ ggtitle(""),
                                  visGroupDirect_200+removeX+removeY+ ggtitle(""),
                        visGroupDirect_222+removeX+removeY+ ggtitle("")
                                 ,ncol =3, nrow = 3)
                                  
      


visGroupDirectJoint2 <- annotate_figure(visGroupDirectJoint, 
                                  top = text_grob("(range restricted to (-4,4), IC at the rounded mean = 5)",
                                                  size = 10))
visGroupJoint3 <- annotate_figure(visGroupDirectJoint2, 
                                  top = text_grob("Predicted direct effect of treatment group by activity profile (standardized)",
                                                  size = 12))

visGroupJoint3
```
\normalsize





Now, predicted direct effect of five interventions vs. \textsf{CBS}, for three user activity profiles.

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
visContrastsCBSDirect <- function(model = FinalHMC, ADS = ADS , CAS= CAS, IC =  5,
                            CBS = seq(-3,3,by  = 0.1)){
  groupID <- 1:3
  data <- expand.grid(ADS, groupID, CAS, IC , CBS)
  colnames(data) <- c("ADS", "groupID", "CAS", "IC", "CBS")
  posterior <- extract.samples(model, n = 1e5)
  link( model, data=data ) 
  mu <- link( model, data=data ) 
  
  means <-  round(apply(mu , 2 , mean ), 4)
  
  HPDIs <- round(apply( mu , 2 , HPDI ),4)
  visContrast <- cbind(data,means,t(as.data.frame(HPDIs)))
  
  ones <- 3 * (1:(nrow(visContrast)/3))-2
  twos <- 3 * (1:(nrow(visContrast)/3))-1
  threes <- 3 * (1:(nrow(visContrast)/3))
  
  colnames(visContrast)[c(7,8)] <- c("low", "high")
  
  contrast <- numeric(nrow(visContrast))
  cLow <- numeric(nrow(visContrast))
  cHigh <- numeric(nrow(visContrast))
  for(i in threes){
    contrast[i] <- visContrast$means[i] - visContrast$means[i-2]  
  }
  for(i in twos){
    contrast[i] <- visContrast$means[i] - visContrast$means[i-1]  
  }
  visContrast$contrast <- contrast
  visContrast$shift <-  visContrast$contrast - visContrast$means
  for(i in ones){
    visContrast$shift[i] <- 0
  }
  visContrast$cLow <- visContrast$low + visContrast$shift
  visContrast$cHigh <- visContrast$high + visContrast$shift
  
  visContrast$group = rep(c("control", "empathy", "normative"), 
                          nrow(visContrast)/3)
  
  visContrastTreatment <- visContrast[groupID !=1,]
  
  return(ggplot(visContrastTreatment, aes(x = CBS, y = contrast, fill = group ))+
           geom_line(se = FALSE)+
           geom_ribbon(mapping = 
                         aes(ymin = cLow, ymax = cHigh),  
                       alpha = .3)+
           theme_tufte()+ylim(c(-3.5,3.5)))
}

visContrastDirect <-  ggarrange(visContrastsCBSDirect(model = tooFarDirect,ADS = -2, CAS = -2, IC = 5)+ggtitle("ADS = CAS = -2")+ scale_fill_discrete(guide=FALSE),
          visContrastsCBSDirect(model = tooFarDirect,ADS = 0, CAS = 0, IC = 5) +ggtitle("ADS = CAS = 0")+ scale_fill_discrete(guide=FALSE)+removeY,
          visContrastsCBSDirect(model = tooFarDirect,ADS = 2, CAS = 2, IC = 5) +ggtitle("ADS = CAS = 2")+ scale_fill_discrete(guide=FALSE)+removeY
          ,ncol =3)


                                 

visContrastDirect2 <- annotate_figure(visContrastDirect, 
                                        top = text_grob("(range restricted to (-3.5,3.5), IC at the rounded mean = 5)",
                                                        size = 10))
visContrastDirect3 <- annotate_figure(visContrastDirect2, 
                                        top = text_grob("Predicted direct effect distance from the control group mean vs. CBS  (standardized)",
                                                        size = 12))

visContrastDirect3
```
\normalsize








Now contrasts against \textsf{ADS}, for three user profiles:

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}

visContrastsADSDirect <- function(model = FinalHMC, CBS = CBS , CAS = CAS, IC =  5, 
                            ADS = seq(-3,3,by  = 0.1))
{
  data <- expand.grid(CBS, groupID, CAS, IC , ADS)
  colnames(data) <- c("CBS", "groupID", "CAS", "IC", "ADS")
  posterior <- extract.samples(model, n = 1e5)
  mu <- link( model, data=data ) 
  means <-  round(apply(mu , 2 , mean ), 4)
  HPDIs <- round(apply( mu , 2 , HPDI ),4)
  visContrastADS <- cbind(data,means,t(as.data.frame(HPDIs)))
  
  
  ones <- 3 * (1:(nrow(visContrastADS)/3))-2
  twos <- 3 * (1:(nrow(visContrastADS)/3))-1
  threes <- 3 * (1:(nrow(visContrastADS)/3))
  
  colnames(visContrastADS)[c(7,8)] <- c("low", "high")
  contrastADS <- numeric(nrow(visContrastADS))
  for(i in threes){
    contrastADS[i] <- visContrastADS$means[i] - visContrastADS$means[i-2]  
  }
  for(i in twos){
    contrastADS[i] <- visContrastADS$means[i] - visContrastADS$means[i-1]  
  }
  visContrastADS$contrast <- contrastADS
  visContrastADS$shift <-  visContrastADS$contrast - visContrastADS$means
  for(i in ones){
    visContrastADS$shift[i] <- 0
  }
  visContrastADS$cLow <- visContrastADS$low + visContrastADS$shift
  visContrastADS$cHigh <- visContrastADS$high + visContrastADS$shift
  
  visContrastADS$group = rep(c("control", "empathy", "normative"), 
                             nrow(visContrastADS)/3)
  visContrastTreatmentADS <- visContrastADS[groupID !=1,]
  
  return(ggplot(visContrastTreatmentADS, aes(x = ADS, y = contrast, fill = group ))+
           geom_line(se = FALSE) +
           geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), 
                       alpha = .3) +theme_tufte())
}





visContrastADSDirectJoint <- ggarrange(
  visContrastsADSDirect(tooFarDirect,CBS = -2, CAS = -2)+ggtitle("CBS = CAS = -2")+ylim(c(-3,3))+ scale_fill_discrete(guide=FALSE),
  visContrastsADSDirect(tooFarDirect, CBS = 0, CAS = 0)+ggtitle("CBS = CAS = 0")+ylim(c(-3,3))+ scale_fill_discrete(guide=FALSE),
  visContrastsADSDirect(tooFarDirect, CBS = 2, CAS = 2)+ggtitle("CBS = CAS = 2")+ylim(c(-3,3))+ scale_fill_discrete(guide=FALSE),
  ncol =3)
  

  
  
visContrastADSDirectJoint2 <- annotate_figure(visContrastADSDirectJoint, 
                                        top = text_grob("(range restricted to (-3,3), IC at the rounded mean = 5)",
                                                        size = 10))
visContrastADSDirectJoint3 <- annotate_figure(visContrastADSDirectJoint2, 
                                        top = text_grob("Predicted direct effect distance from the control group mean vs. ADS (standardized)",
                                                        size = 12))

visContrastADSDirectJoint3
```
\normalsize









#  References {-}

\vspace{-3mm}








