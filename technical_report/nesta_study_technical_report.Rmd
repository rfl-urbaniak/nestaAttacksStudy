---
title: "Bayesian analysis of the NESTA study of interventions against  verbal aggression online \\linebreak  Technical Report"
author: "Rafal Urbaniak"
output:
  pdf_document:
  number_sections: yes
  keep_tex: yes
df_print: kable
includes:
  in_header: Rafal_latex8.sty
html_document:
  df_print: paged
word_document: default
classoption: dvipsnames, enabledeprecatedfontcommands
fontsize: 10pt
documentclass: scrartcl
urlcolor: blue
bibliography: ../references/attacks.bib
csl: ../references/apa-6th-edition.csl
---
  









```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = '../')

#libraries used
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(kableExtra)
library(viridis)
library(rethinking)
library(ggplot2)
library(ggpubr)
library(tidyverse)
library(GGally)
library(dagitty)
library(reshape)
library(lubridate)
library(formatR)
library(ggrepel)



mykable <- function(object) {kable(object, "latex", booktabs = T,linesep = "") %>% kable_styling(latex_options = "striped",font_size = 9)}  

removeX <-   theme(axis.title.x=element_blank(),
                   axis.text.x=element_blank(),
                   axis.ticks.x=element_blank())

removeY <-   theme(axis.title.y=element_blank(),
                   axis.text.y=element_blank(),
                   axis.ticks.y=element_blank())

knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 70), tidy = FALSE)

#kable(table(data$group), "latex", booktabs = T, col.names = c("Group", "n")) %>% 
#  kable_styling(latex_options = c("striped","HOLD_position"),font_size = 9) 
```


\tableofcontents





# Data and exploration



\vspace{1mm}
\scriptsize

```{r periodsVisualisationPrep,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE, tidy = FALSE}
Hate <- readRDS(file = "datasets/RAWNESTA/Hate.rds")
Comments <-   readRDS(file = "datasets/RAWNESTA/Comments.rds")
summaries <- read.csv(file = "datasets/Summaries.csv")

summaries$ABS <- standardize(summaries$AB)
summaries$CBS <- standardize(summaries$CB)
summaries$AAS <- standardize(summaries$AA)
summaries$CAS <- standardize(summaries$CA)
summaries$CDS <- standardize(summaries$CD)
summaries$ADS <- standardize(summaries$AD)
summaries$group <- as.factor(summaries$group)
summaries$groupID <-  as.integer( as.factor(summaries$group) )


dates <- colnames(Hate)[-1]
dates <- as.Date(dates)
startDate <- dates[1]
interventionDate <- "2020-07-08"
observationDate <- "2020-09-09"
end <- dates[length(dates)]

periods<- numeric(length(dates))
periods <- ifelse(dates < interventionDate,"pre-treatment",periods)
periods <- ifelse(dates >= interventionDate & dates < observationDate,"treatment",periods)
periods <- ifelse(dates >= observationDate,"post-treatment",periods)

hateTS <- as.data.frame(colSums(Hate[,-1]))
hateTS$date <- as.Date(rownames(hateTS))
rownames(hateTS) <- NULL
colnames(hateTS) <- c("attacks","date")
hateTS$periods <- periods

interventions <- readRDS(file = "datasets/interventions.rds")
interventionsTS <- as.data.frame(table(interventions$day))
interventionsTS$Var1 <- as.Date(interventionsTS$Var1)
colnames(interventionsTS) <- c("date", "interventions")

periodsDF <- merge(x = hateTS, y = interventionsTS, by = "date", all.x = TRUE)

idx <- c(1, diff(periodsDF$date))
i2 <- c(1,which(idx != 1), nrow(periodsDF)+1)
periodsDF$grp <- rep(1:length(diff(i2)), diff(i2))

periodsDF$interventions[is.na(periodsDF$interventions) & periodsDF$periods == "treatment"] <- 0

periodsPlot <- ggplot(periodsDF)+
  geom_line(aes(x=date, y = attacks, group = grp),
             alpha = 0.8, size = .6)+
  geom_line(aes(x=date, y = interventions, group = grp),
            alpha = 0.8, size = .6)+
  geom_vline(xintercept = startDate, lty =2, size =.2, alpha=0.5)+
  geom_vline(xintercept = as.Date(interventionDate), lty =2, size =.2, alpha=0.5)+
  geom_vline(xintercept =  as.Date(observationDate), lty = 2, size =.2, alpha=0.5 )+
  geom_vline(xintercept = as.Date(end), lty =2, size =.2, alpha=0.5)+
  labs(title = "Personal attacks and interventions time series",
       subtitle = "no line at data gaps", 
       caption = 
    "days with data: 81 (pre-treatment), 62 (treatment), 72 (post-treatment)")+
  theme_tufte() + theme(axis.title.x=element_blank(), 
  plot.caption = element_text(hjust = 0.5,  face= "italic"),
  plot.title = element_text(size=17),
  plot.title.position = "plot")+
  scale_x_date(date_labels = "%b %d", breaks = c(startDate, as.Date(startDate),
              as.Date(interventionDate),  as.Date(observationDate), end), 
              limits = c(startDate-30,end+10))+ylab("count")+
  annotate("rect", xmin = as.Date(interventionDate), xmax = as.Date(observationDate),
           ymin = -1, ymax = 360,
           alpha = .2,fill = "darkgreen")+ylim(c(-1,370))+
  annotate("text", label = "pre-treatment", x = as.Date(startDate)+2, y = 370, hjust =0 )+
  annotate("text", label = "treatment", x = as.Date(interventionDate)+2, y = 370, hjust =0 )+
  annotate("text", label = "post-treatment", x = as.Date(observationDate)+2, y = 370, hjust =0 )+
  annotate("text", label = "interventions:", x = as.Date(interventionDate)-55, y = 15, hjust =0 )+
  annotate("text", label = "attacks:", x = as.Date(startDate)-30, y = 215, hjust =0 )

periodsDF$weekdays <-  weekdays(as.Date(periodsDF$date))
periodsDF$weeks <-  week(as.Date(periodsDF$date))

periodsDF$weekdays <- as.factor(periodsDF$weekdays)
levels(periodsDF$weekdays) <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday",
                                "Saturday", "Sunday")
weeksPlot <- ggplot(periodsDF)+
  geom_smooth(aes(x = weekdays, y = attacks, group =1))+
  geom_line(aes(x = weekdays, y = attacks, group = weeks),alpha = 0.1)+
  theme_tufte()+labs(title="Personal attacks vs weekdays (six months)", subtitle = "no weekly patterns")+xlab("")+
  ylab("attacks per day")+ theme(plot.title.position = "plot",
  plot.title = element_text(size=17))
```
\normalsize


For the duration of the project we selected `r length(unique(summaries$author))` Reddit users  and tracked their activity (with some breaks resulting from API restrictions and technical issues, which were mostly sorted out in the observation period), starting on 
`r startDate`, beginning the intervention period on `r interventionDate`, leading to a further observation period starting on  `r observationDate` and ending on  `r end`. The time series of attacks observed and of interventions conducted can be inspected in Figure \ref{fig:periodsPlot}, along with a quick search for weekly patterns. Some of the users turned out to be bots, a few ceased to be active during the experiment (with no strong reason to think this happened due to them receiving an intervention) and a few received treatment of two different types by accident (we relied on multiple volunteers and such mistakes were likely to happen). Ultimately, in the time series data, we ended up with  data on 440 users.





\begin{figure}[H]
```{r periodsPlot,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "48%", warning = FALSE, message = FALSE}
periodsPlot
weeksPlot
```
\caption{Daily sums of attacks and interventions throughout the three experimental periods, with GAM smoothing (left) and daily attack sums from all  weeks in the experimental period plotted against week days (right)---no pattern seems to arise.}
\label{fig:periodsPlot}
\end{figure}






We analyzed the data from three perspectives: we used the daily data to (1) build seven time series models estimating the impact of individual interventions at lags 1-7 days, and (2) to study the impact of the cumulative number of total interventions received as the experiment progressed, and then we used aggregated data to run a long term before-and after analysis, comparing the summarized aggression levels before and after the intervention period.


Before we move to the analysis, let us inspect the data. First, at the aggregated level, the data involve the variables listed in Table \ref{tab:baaVars}.\footnote{Further variables were defined in terms of those, in particular, we will be predicting \textsf{AdiffS} which is the standardized difference  \textsf{AA}-\textsf{AB}, and \textsf{AdiffS}, which is the standardized difference \textsf{CA}-\textsf{CB}.The  standardized variables are systematically named  $\langle$variable\char`_name$\rangle$S.}


\vspace{1mm}
\footnotesize
```{r varsTablePrep,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
variable <- c("AB", "AD", "AA", "CB", "CD", "CA", "group", "IC")
explanation <- c("attacks before (pre-treatment)", "attacks during (the treatment period)",
                 "attacks after (post-treatment)", "comments before", "comments during",
                 "comments after", "treatment group", "intervention count")
vars <- data.frame(variable, explanation)
#mykable(vars)
```
\normalsize


\begin{table}
\centering
\begin{tabular}{ll}
\toprule
variable & explanation\\
\midrule
\cellcolor{gray!6}{AB} & \cellcolor{gray!6}{attacks before (pre-treatment)}\\
AD & attacks during (the treatment period)\\
\cellcolor{gray!6}{AA} & \cellcolor{gray!6}{attacks after (post-treatment)}\\
CB & comments before\\
\cellcolor{gray!6}{CD} & \cellcolor{gray!6}{comments during}\\
CA & comments after\\
\cellcolor{gray!6}{group} & \cellcolor{gray!6}{treatment group}\\
IC & intervention count\\
\bottomrule
\end{tabular}

\caption{Variables involved in the before-and-after analysis.}
\label{tab:baaVars}
\end{table}





The distribution of \textsf{IC} in the treatment groups is visualized in Figure \ref{fig:interventionsDistro}. Note that the distributions are somewhat different, even though the total intervention counts are similar. The issue is discussed in Section XXXXX.

<!-- TODO REF -->


\vspace{1mm}
\footnotesize
```{r interventionsDistroPrep,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
interventionsDistro2 <- ggplot(summaries[summaries$group != "control",],
  aes(x = IC, fill = group))+
  geom_bar()+theme_tufte()+
  xlab("interventions received")+
  labs(title = "Total intervention counts by users and treatment groups")+
  scale_x_continuous(breaks = seq(0,40,5))+ 
  theme(plot.title.position = "plot",legend.position = c(0.8, 0.8))+
  scale_fill_manual(values=c("dodgerblue4", "orangered"))+ylab("number of users")
```
\normalsize


\begin{figure}[H]
```{r interventionsDistroPlot,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
interventionsDistro2
```
\caption{Distribution of daily interventions (by treatment group).}
\label{fig:interventionsDistro}
\end{figure}



Second, in the distribution of standardized difference in attacks,  the peaks of distributions are shifted a bit between the groups, with lowest median for the normative group, but the differences seem minor (Figure \ref{fig:violJoint}).  This might suggest no impact of the interventions. This conclusion would be too hasty, as the impact of  other predictor variables and interactions involved can mask actual associations. 




\vspace{1mm}
\footnotesize
```{r violEmpiricalAdiff,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
violAdiffS3 <- ggplot(summaries, aes(x=group, y = AdiffS, color = group))+
  geom_violin() +theme_tufte() +theme(plot.title.position = "plot")+
  ylab("change in attacks (standardized)")+  
  scale_color_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
  theme(legend.position = c(0.8, 0.2))

violAddifS3restr <- violAdiffS3 + ylim(c(-1,1))+geom_boxplot(width = .2)+ 
  ggtitle("restricted to (-1,1)") + 
  theme(plot.title.position = "plot", legend.position = "none")

 violJoint3 <- ggarrange(violAdiffS3+ggtitle("whole range")+
  theme(plot.title.position = "plot"),  violAddifS3restr)

violJointTitled3 <- annotate_figure(violJoint3,
  top = text_grob("Empirical distribution of change in attacks (standardized)",
                   size = 12))
```
\normalsize


\begin{figure}[H]
```{r violJoint,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
violJointTitled3
```
\caption{Empirical distribution of change in attacks (by treatment group).}
\label{fig:violJoint}
\end{figure}



To see how this masking can occur, let us inspect changes in attacks against intervention
counts. It turns out that restricting attention to various aggression levels in the before period results in
fairly strong changes to the regression lines (Figure \ref{fig:linearShift}). This suggests we should keep an eye out for interactions with aggression before in the analysis, and that the initial comparison of means or medians between groups might be misleading if the effects in different volume groups are different and to some extent cancel each other.



\vspace{1mm}
\footnotesize
```{r icPrep,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
icplot1b <- ggplot(summaries, 
          aes(x = IC, y = AdiffS, color = group, fill = group)) +
      geom_jitter(alpha = 0.6, size = 0.8) +
      theme_tufte() +
      geom_smooth(alpha = 0.2, method = "lm", size = .5) + 
      xlim(c(0, 25)) + ylim(c(-2, 2)) +
      ggtitle("y restricted to (-2,2)") + 
      theme(legend.position = c(0.65, 0.2), plot.title.position = "plot") +
      ylab("change in attacks (standardized)")+  
  scale_color_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+  
  scale_fill_manual(values=c("darkgreen", "dodgerblue4", "orangered"))

icplot2b <- ggplot(summaries, 
          aes(x = IC, y = AdiffS, color = group, fill = group)) +
      geom_jitter(alpha = 0.6, size = 0.8) + 
      theme_tufte() +
      geom_smooth(alpha = 0.2, method = "lm", size = .5) + 
      xlim(c(0, 25)) + ylim(c(-1, 1)) + 
      ggtitle("y restricted to (-1,1)") + 
      theme(plot.title.position = "plot",legend.position = "none") +  
      ylab("change in attacks (standardized)")+  
      scale_color_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
      scale_fill_manual(values=c("darkgreen", "dodgerblue4", "orangered"))

icplotJointb <- ggarrange(icplot1b, icplot2b) 
icplotTitledb <- annotate_figure(icplotJointb, 
  top = text_grob("Change in attacks (standardized) vs interventions received", 
                  size = 12))
```




\begin{figure}
```{r fig:linearShift,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
icplotTitledb 
```
\caption{Change in attacks vs the number of interventions received by treatment group, jittered with  linear smoothing.}
\label{fig:linearShift}
\end{figure}

\normalsize 
Further insights, undermining the initial impression suggested by Figure \ref{fig:violJoint}, can be obtained by visualizing individual time series. Figure \ref{fig:tsVis} contains  six fairly typical examples. 




\vspace{1mm}
\footnotesize
```{r tsVisPrep,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
hateDFs <- readRDS("datasets/hateDFsNoDropouts.RDS")


start <- as.Date("2020-03-09")
treatment <- as.Date("2020-07-08")
observation <- as.Date("2020-09-09")
end <- as.Date("2020-11-20")

plotUser <- function(user, divider =5){
  ggplot(hateDFs[[user]])+
    geom_point(aes(x = day, y = attacks, group = user), alpha = .4, size = .4)+
    geom_smooth(aes(x = day, y = attacks), size = .5)+
    geom_line(aes(x = day, y = intCL3D/10), color = "orangered", alpha = .8)+
    theme_tufte(base_size = 7)+xlab("")+ 
    geom_vline(xintercept = as.Date("2020-07-08"),
               lty = 2, size = 0.2, alpha = 0.5)+
    geom_vline(xintercept = as.Date("2020-09-09"),
               lty = 2, size = 0.2, alpha = 0.5)+
    annotate("rect", xmin = as.Date("2020-07-08"),
             xmax = as.Date("2020-09-09"), ymin = -.5, 
             ymax = max(hateDFs[[user]]$attacks* 1.05),
             alpha = 0.2,  fill = "darkgreen")+
    geom_smooth(aes(x = day, y = act/divider), 
                color = "grey", alpha = .5, se = FALSE, size = .4)+
    ggtitle(paste("User ", user, " (", ifelse(hateDFs[[user]]$type[1] == "emp",
                                              "empathy", ifelse(hateDFs[[user]]$type[1] == "norm",
                                                                "normative", "control")),")", sep = ""))+
    labs(subtitle = paste("ABS =", round(hateDFs[[user]]$ABS[1],3),
                          ", activity divider=", divider,sep = ""))+
    theme(plot.title.position = "plot", plot.title = element_text(size=16))  + 
    annotate("text", x = as.Date("2020-05-11"), y = -.7, label = "pre-treatment", size = 3.5)+ 
    annotate("text", x = as.Date("2020-08-11"), y = -.7, label = "treatment", size = 3.5)+ 
    annotate("text", x = as.Date("2020-10-11"), y = -.7, label = "post-treatment", size = 3.5)+
    theme(plot.title.position = "plot")+
    scale_x_date(date_labels = "%b %d", breaks = c(start, treatment, observation,  end))
}

c1plot <- plotUser(34, divider = 10)
c2plot <- plotUser(22, divider = 4)
n1plot <- plotUser(39, divider = 8)
n2plot <- plotUser(2, divider = 6)
e1plot <- plotUser(231, divider = 4)
e2plot <- plotUser(112, divider = 4) + ylim(0,1.5)

individualTSplot3 <- ggarrange(c1plot, e1plot, n1plot, c2plot, e2plot,  n2plot)
individualTSplotTitled3 <- annotate_figure(individualTSplot3,
  top = text_grob("Individual time series by group and activity (examples)",  
                  size = 12))
```




\begin{figure}
```{r fig:tsVisPlot,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
individualTSplotTitled3
```
\caption{Examples of individual time series. Black points are attacks (smoothed in blue), red lines represent the cumulative number of interventions received (lag 3) divided by 10, gray lines represent overall activity level divided by a variable divider listed in the subtitle. Divisions introduced for visual comparability of general trends.}
\label{fig:tsVis}
\end{figure}

\normalsize

The general phenomenon is that while in the control group attacks tend not to diminish, unless activity itself diminishes, they tend to diminish in the normative group (although the more aggressive the user is, the less of an impact can be observed), and in the empathetic group if the user is not very aggressive. Of course, visualization of individual cases (which the reader might suspect to be cherry-picked) is no replacement for statistical analysis, to which we will now move.





# Causal thinking, choice of variables and models


First, we inspect correlations between predictors to avoid, and develop a plausible causal model of the situation (Figure \ref{fig:correlations}). It turns out that to avoid multicolinearity we cannot  condition on CDS if we condition on CAS or CBS. Similarly, for the time series data, since activity levels in  particular day slices are correlated, it will  not be useful to condition on more than one auto-regressive element (and since the predictive power is the highest for lag 1 with no discoverable weekly patterns, we will not go further than lag 1). 


To identify the right variables to condition (or not condition) on to identify the causal effect of the interventions, we need to think about the causal structure of the problem. Comments during impact attacks during, which trigger interventions. Unmeasured user features cause comments before, which impact attacks before directly. Comments during (their impact on ADS is already included)  impact attacks during  directly and  comments after, which impact attacks after and   attacks after directly.  Intervention count impacts attacks after  and comments after. The same directions of impact are included for intervention type. Finally, comments through time are connected causally, and so are attacks. The structure for the time series data is analogous, except now instead of before and after, we have multiple daily indices.  




\vspace{1mm}
\footnotesize
```{r dag1,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "80%"}
dag <- dagitty("
  dag{
  CDS -> ADS -> IC  
               U [unobserved]   
               U -> CBS -> ABS  
               U -> ABS        
               U -> CDS -> ADS  
               U -> ADS         
               U -> CAS -> AAS    
               U -> AAS                        
               IC -> AAS        
               IC -> CAS        
               IT -> CAS        
               IT -> AAS
               CBS -> CDS -> CAS
               ABS -> ADS -> AAS
               }")
coordinates( dag ) <- list(x=c(CBS=0,ABS=0,CDS=1,ADS=1, CAS = 2,
                               AAS = 2, IT = 1.5, IC = 1.5, U = .5) ,
                            y=c(CBS =0,ABS = 1,CDS = 0,ADS = 1,
                                CAS = 0, AAS = 1, IT = .3, IC = .7, U =.5) )
```
\normalsize







\begin{figure}[H]
```{r correlations,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "48%",   message = FALSE, warning = FALSE, results = FALSE}
summariesCorr <- select(summaries, IC, ABS, CBS, AAS, CAS, CDS, ADS)
ggcorr(summariesCorr, method = c("pairwise"),
       digits = 4, low = "steelblue", mid = "white",
       high = "darkred", midpoint =0,
       geom = "tile", label = TRUE, label_size=4, label_round =2, layout.exp =1,
       label_alpha = FALSE,hjust = 0.75)+ggtitle("Only activity levels through time are strongly correlated")

drawdag(dag)  
```

\caption{Correlations between predictors (left) and a plausible causal model (right) used in the before-and-after analysis.}
\label{fig:correlations}
\end{figure}






What do we learn from  causal considerations? \textsf{IT} has no backdoor paths, but \textsf{IC} does, so we need to make sure these are closed to avoid including spurious correlations in our analysis. There are in fact 65 different paths from \textsf{IC} to \textsf{AAC}. Crucially,  all backdoor paths go through \textsf{ADS}, which then becomes either a fork or a pipe, so all backdoor paths can be closed by conditioning on \textsf{ADS}. Moreover there is only one directed indirect path, it goes through \textsf{CAS}, so we should not condition on \textsf{CAS} if we are to identify total  causal effect of \textsf{IC} on attacks, including the impact  mediated by its impact on comments. We might be interested in  the direct effect of \textsf{IC}  and \textsf{IT} on \textsf{AAS}, but then we also need to block indirect causal paths from the intervention to the outcome. For such an evaluation we would need to also condition on \textsf{CAS} and block all backdoor paths from \textsf{CAS} to \textsf{AAS}. This, however, given the causal model, cannot be achieved, as it would required conditioning on unobserved user features. That is, we do not think direct causal effect is identifiable. 

Analogous considerations apply to the time series model for the total impact of individual interventions received exactly $k$ days before (in our case, $k\in \{1, \dots, 7\}$). The situation, however, is somewhat different for the impact of the total number of cumulative interventions received so far. The trouble is, for example, that if a user received so far a number  interventions until yesterday, some of them had been received before yesterday and those had already impacted the aggression level yesterday. In other words, conditioning on lagged attacks leads to the post-treatment bias and should be avoided.\footnote{In fact, in the aggregated data analysis, we will be predicting the standardized difference between attacks before and after (\textsf{ADiffS}), and the standardized difference between comments, before and after (\textsf{CDiffS}), but the general points about the nodes involved apply also to defined nodes.  As already discussed, we do not include \textsf{CDS} because of its strong correlation with \textsf{CBS}. We also do not condition on \textsf{ABS} when modeling \textsf{ADiffS} (or on \textsf{CBS} when modeling \textsf{CDiffS})---not only because it has a pretty strong correlation with another predictor (\textsf{ADS}), but rather also because it is used to define the output variable. In such a set-up, it is clear that a model including \textsf{ABS} would have better predictive power, but since a definitional connection is present, thinking that its inclusion in the model tells us something about causality  would be misled.}   


Otherwise, it's open season for the  other variables and interactions between them, and our decision to include or exclude them in the model will be guided by    information-theoretic criteria of predictive power (\textsf{WAIC}, the so-called \emph{Widely Acceptable Information Criterion}),\footnote{
Here's a more detailed explanation of the model comparison method we used, uninterested reader is invited to skip forward. Let  $y$ be the observations and $\Theta$  a posterior distribution.
First, log-pointwise-predictive-density is defined by:
\begin{align*}
\mathsf{lppd}(y, \Theta) & = \sum_i log\frac{1}{S}\sum_s p (y_i\vert \Theta_s)
\end{align*}
\noindent where $S$ is the number of samples in the posterior, and $\Theta_s$ 
is the $s$-th combination of sampled parameter values in the posterior distribution. That is, 
for each observation and each combination of 
parameters in the posterior we first compute its density, then 
we take the average density of that observation over all combinations of parameters in the posterior,
and  then take the logarithm. Finally, we sum these values up for all the observations. Crucially, when comparing posterior distributions with respect to the same dataset, \textsf{lppd}s are proportional
 to unbiased estimates of their divergence from the real distribution (note that it is \emph{only} 
 proportional, and for this reason can be used for comparison of distributions 
 only and makes no intuitive sense on its own).  However, \textsf{lppd} always improves
  as the model gets more complex, so for model comparison it makes more sense to use 
 the Widely Applicable Information Criterion (WAIC), which is an approximation of the out-of-sample deviance that converges to the cross-validation approximation in a large sample. It  is defined as
 the log-posterior-predictive-density with an additional
  penalty proportional to the variance in the
  posterior predictions:
  \begin{align*}
\mathsf{WAIC(y, \Theta)} & = -2 (\mathsf{lppd} - \overbrace{\sum_i var_\theta \mathsf{log} p (y_i \vert \theta)}^{\mathsf{penalty}})
  \end{align*}
\noindent  Thus to construct the penalty, we calculate the variance in log-probabilities for each observation and sum them up. Because of the analogy to Akaike's criterion, the penalty is sometimes called the effective number of parameters, $p_{\mathsf{WAIC}}$. 
How does WAIC compare to other information criteria?  AIC uses MAP estimates instead of the posterior and requires that priors be flat or overwhelmed by the likelihood, and assumes that the posterior distribution is approximately multivariate Gaussian and the sample size is  much greater  than the number of parameters used in the model. Bayesian Information Criterion (BIC) also requires flat priors and uses MAP estimates. WAIC does not make these assumptions, and provides almost exactly the same results as AIC, when AIC’s assumptions are met.} or posterior predictive checks in cases in which the  likelihood functions used by the models to be compared are different and information-theoretic calculations might be misleading. In such cases we investigated the ratio of actual observations included in the 50\% and in the 89\% posterior predictive distribution, and the models for which higher ratios were observed in both were selected (no case of diverging evaluation for the two criteria has been observed). 

In our model building we will be using the \textsf{rethinking} package, except for the cumulative impact time series models, where it becomes computationally unfeasible, in which case we build models in \textsf{Rstan} directly. Moreover, for the time series analysis we will build hierarchical Bayesian models which tend to have around $u \times 2p + 2p$ parameters (we will explain later why), which means that for 440 users our final model with interaction with six predictors would have $440 \times 12 + 12 = 5292$ parameters, and the model would have to be trained on six months of daily data for 7 variables. The building of such a model on a modern computer takes days. Since in reaching this model we needed to build multiple somewhat simpler models or models with  different structures and test their performance, model selection on the full data set was unfeasible. That is, in the time series analysis in model selection at each step we compared models (sometimes built with quadratic approximation) with respect to three independent samples for $40, 60$ and $60$ users. We made the decision only if a given model structure performed better in all these subsets (which was usually the case, so the model selection criteria gave us pretty robust answers). For the most complicated model of the impact of cumulative number of interventions, building a single model for the whole data set was not computationally feasible (computation time does not increase linearly with the number of users included in the dataset), so we randomly split the dataset into four and provided results for all of them. The results were not very divergent. 




# Time series model selection


Suppose we are interested in the impact of interventions received $n$ days ago. We started with a simple null model that uses the Poisson distribution, with either uses a single $\lambda$ for all the users, or user-specific $\lambda$s. The first Bayesian model has the following structure:
\begin{align*}
\mathsf{attacks_i} & \sim  \textsf{Poisson}( \lambda)\\ 
    log(\lambda)  & =  l \\
    l & \sim  \textsf{Norm}(.05,2.8)
\end{align*}

and the user-specific coefficient model had the following structure:
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{Poisson}( \lambda_i)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} \\
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.8)
\end{align*}

\footnotesize
```{r nullTSmodels,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
dat <- readRDS(file = "datasets/dat.RDS")

lmu <- .05
lsigma <- 2.8
  
nullPoisson <-  quap(
  alist(
    attacks ~ dpois( lambda),
    log(lambda) <- l,
    l ~ dnorm(lmu,lsigma)
  ), data=datA)

#prior predictive check
prior <- extract.prior( nullPoisson , n=1e4 )
lambda <- exp(prior$l) 
priorPlot <- ggplot()+ geom_density(aes(x = lambda))+xlim(c(0,50))+
  ggtitle("Lambda")+theme_tufte()

nullPoissonUser <-  quap(
  alist(
    attacks ~ dpois( lambda),
    log(lambda) <- l[userID],
    l[userID] ~ dnorm(lmu,lsigma)
  ), data=dat)

compare(nullPoisson, nullPoissonUser)
```
\normalsize


The priors were chosen using prior predictive check, so that the 89\% density intervals reached between 0 and 34, with median around 1. Given our prior experience with similar user datasets this is a fairly wide informative prior. The comparison, unsurprisingly, preferred the user-specific $\lambda$s. 

Next, we introduced the auto-regressive element, conditioning on yesterday's attacks. The choice of priors for the auto-regression coefficient is guided by the visualization (intuitive direct understanding of the values is made difficult by the fact that the predictors work on the logarithmic scale) and the fact that larger values would result in a unreasonably  extreme impact of yesterday's attacks. 
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{Poisson}( \lambda_i)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.8)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.2)
\end{align*}

\footnotesize
```{r AR1TSmodels,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
amu <- 0
asigma <- .2

AR1Poisson <-  quap(
  alist(
    attacks ~ dpois( lambda),
    log(lambda) <- l[userID] + a[userID] * attacksL1,
    l[userID] ~ dnorm(lmu,lsigma),
    a[userID] ~ dnorm(amu, asigma)
  ), data=dat)

prior <- extract.prior( AR1Poisson , n=1e4 )

N <- 300
plot( NULL , xlim=c(0,40) , ylim=c(0,200) )
for ( i in 1:N ) curve( exp( prior$l[i,1] + prior$a[i,1]*x ) , add=TRUE , col=grau() )

compare(AR1Poisson,nullPoissonUser)
```
\normalsize

Next,  we  added today's activity level as a predictor, with  user-specific coefficients. Adding activity levels helps. Note also that our priors taken separately were made more narrow, to preserve the overall width of the prior predictive distribution (this will be the usual strategy as we progress).
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{Poisson}( \lambda_i)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c * \mathsf{act}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c & \sim  \textsf{Norm}(0,.1)
\end{align*}
\noindent Unsurprisingly, it helps even more if the coefficients are user-specific:
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{Poisson}( \lambda_i)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1)
\end{align*}

\footnotesize
```{r AR1CTSmodels,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
lmu <- .05
lsigma <- 2.3
amu <- 0
asigma <- .1
cmu <- 0
csigma <- .1

AR1CSimplePoisson <-  quap(
  alist(
    attacks ~ dpois( lambda),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c * act,
    l[userID] ~ dnorm(lmu,lsigma),
    a[userID] ~ dnorm(amu, asigma),
    c ~ dnorm(cmu, csigma)
  ), data=dat)

AR1CPoisson <-  quap(
  alist(
    attacks ~ dpois( lambda),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act,
    l[userID] ~ dnorm(lmu,lsigma),
    a[userID] ~ dnorm(amu, asigma),
    c[userID] ~ dnorm(cmu, csigma)
  ), data=dat)
```
\normalsize

A relatively large number of zeros  suggests that  moving to a zero-inflated Poisson distribution would be a good idea. It was not, so the following model structure was tested and abandoned:
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{ZiPoisson}(p, \lambda_i)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1) \\
    logit(p) & = \pi\\
    \pi & \sim Norm(-1.5,1) 
\end{align*}

\footnotesize
```{r AR1CZiTSmodels,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
AR1Czi <-  quap(
  alist(
    attacks ~ dzipois(p, lambda),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act,
    l[userID] ~ dnorm(lmu,lsigma),
    a[userID] ~ dnorm(amu, asigma),
    c[userID] ~ dnorm(cmu, csigma),
    logit(p) <- pp,
    pp ~ dnorm(-1.5,1)
  ), data=dat)
```
\normalsize


Then we considered the negative binomial distribution, and the addition of week days as a predictor (both with general and user-level coefficients). While moving to the negative binomial distribution resulted in an improvement, adding week days did not improve the model performance, perhaps because we already conditioned on activity, and whatever the impact of weekdays was, has been already  mediated through activity (in a sense, we committed a post-treatment bias with respect to weekdays; but that's fine, we did not really care about the impact of weekdays).
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{NegativeBinomial}(\lambda_i, \phi)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1) \\
    \phi& \sim Exp(1)\\
\end{align*}
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{NegativeBinomial}(\lambda_i, \phi)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act} + w * \mathsf{weekday}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1) \\
    w & \sim \textsf{Norm}(0,.1) \\
    \phi & \sim Exp(1)\\
\end{align*}
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{NegativeBinomial}(\lambda_i, \phi)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act} + w_{\mathsf{userID[i]}} * \mathsf{weekday}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1) \\
    w_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1) \\
    \phi & \sim Exp(1)\\
\end{align*}

\footnotesize
```{r AR1CnBinomTSmodels,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
AR1CnBinomUlam <-  ulam(
  alist(
    attacks ~ dgampois( lambda, phi),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act,
    l[userID] ~ dnorm(.05,2.3),
    a[userID] ~ dnorm(0, .1),
    c[userID] ~ dnorm(0, .1),
    phi ~ dexp(1)
  ), data=dat, log_lik = TRUE)

AR1CnBinomUlamW <-  ulam(
  alist(
    attacks ~ dgampois( lambda, phi),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act + w * weekday,
    l[userID] ~ dnorm(.05,2.3),
    a[userID] ~ dnorm(0, .1),
    c[userID] ~ dnorm(0, .1),
    w ~ dnorm(0,.1),
    phi ~ dexp(1)
  ), data=dat, log_lik = TRUE)


AR1CnBinomUlamWu <-  ulam(
  alist(
    attacks ~ dgampois( lambda, phi),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act +
      w[userID] * weekday,
    l[userID] ~ dnorm(.05,2.3),
    a[userID] ~ dnorm(0, .1),
    c[userID] ~ dnorm(0, .1),
    w[userID] ~ dnorm(0,.1),
    phi ~ dexp(1)
  ), data=dat, log_lik = TRUE)
```
\normalsize

We also considered adding overall aggression in before period as a predictor, but the addition did not lead to improvement. One reason this is interesting is that interaction of interventions with overall aggression will  turn out to be important for long-term effects.
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{NegativeBinomial}(\lambda_i, \phi)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act} + act + ab_{\mathsf{userID[i]}} * \textsf{ABS}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1) \\
    ab_{\mathsf{userID[i]}} &   \sim  \textsf{Norm}(0,.1) \\
    \phi & \sim Exp(1)\\
\end{align*}


\footnotesize
```{r AR1CnBinomTSmodelsAB,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
AR1nBinomAB <-  ulam(
  alist(
    attacks ~ dgampois( lambda, phi),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act +
      abs[userID] * abs,
    l[userID] ~ dnorm(.05,2.3),
    a[userID] ~ dnorm(0, .1),
    c[userID] ~ dnorm(0, .1),
    abs[userID] ~ dnorm(0, .1),
    phi ~ dexp(1)
  ), data=dat, log_lik = TRUE)
```
\normalsize




\noindent So, ultimately, the negative binomial model without week days or aggression before became our null model to which we considered adding intervention count and intervention types as predictors. For now, consider intervention type and interventions received with lag 1 (note that if, for instance, we are interested in the impact of interventions lag 2, we cannot condition on interventions lag 1, as this would lead to post-treatment bias). So what we will say about lag 1 will be exactly mirrored in the models for other lag values.


Adding intervention count, and adding intervention count with distinguishing intervention types resulted in improvements.
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{NegativeBinomial}(\lambda_i, \phi)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act} +
      i1 * \mathsf{intL1D}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1) \\
    i1 & \sim  \textsf{Norm}(0,.1) \\
    \phi & \sim Exp(1)\\
\end{align*}
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{NegativeBinomial}(\lambda_i, \phi)\\ 
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act} +
      i1_{\mathsf{type[i]}} * \mathsf{intL1D}\\ 
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1) \\
    i1_{\mathsf{type[i]}} & \sim  \textsf{Norm}(0,.1) \\
    \phi & \sim Exp(1)\\
\end{align*}





\footnotesize
```{r D1TSmodels1,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
daysL1notype <-  ulam(
  alist(
    attacks ~ dgampois( lambda, phi),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act + 
        i1 * intL1D,
    l[userID] ~ dnorm(.05,2.3),
    a[userID] ~ dnorm(0, .1),
    c[userID] ~ dnorm(0, .1),
    i1 ~ dnorm(0, .1),
    phi ~ dexp(1)
  ), data=dat, log_lik = TRUE)


daysL1 <-  ulam(
  alist(
    attacks ~ dgampois( lambda, phi),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act +
        i1[type] * intL1D,
    l[userID] ~ dnorm(.05,2.3),
    a[userID] ~ dnorm(0, .1),
    c[userID] ~ dnorm(0, .1),
    i1[type] ~ dnorm(0, .1),
    phi ~ dexp(1)
  ), data=dat, log_lik = TRUE)
```
\normalsize


Taking  $\phi$ parameters to be  user-relative also resulted in improvement:
\begin{align*}
\mathsf{attacks}_i & \sim  \textsf{NegativeBinomial}(\lambda_i, \phi_{\mathsf{userID[i]}} )\\
    log(\lambda_i)  & =  l_{\mathsf{userID[i]}} + a_{\mathsf{userID[i]}} * \mathsf{attacksL1} + c_{\mathsf{userID[i]}} * \mathsf{act} + i1 * \mathsf{intL1D}\\
    l_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(.05,2.3)\\
    a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(0,.1)\\
    c_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(0,.1) \\
    i1_{\mathsf{type[i]}} & \sim  \textsf{Norm}(0,.1) \\
    \phi_{\mathsf{userID[i]}}  & \sim Exp(1)\\
\end{align*}


\footnotesize
```{r D1TSmodels2,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
daysL1phiuser <-  ulam(
  alist(
    attacks ~ dgampois( lambda, phi),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act +
        i1[type] * intL1D,
    l[userID] ~ dnorm(.05,2.3),
    a[userID] ~ dnorm(0, .1),
    c[userID] ~ dnorm(0, .1),
    i1[type] ~ dnorm(0, .1),
    phi <- puser[userID],
    puser[userID] ~ dexp(1)
  ), data=dat, log_lik = TRUE)
```
\normalsize



Finally, we made a crucial move to deploy hierarchical modeling. The general idea is that while we do keep user-specific coefficients wherever we had them, we also do not assume that they are independent, but rather that they come from their respective distributions, and we estimate the general features of those distributions at the same time. Also, for convenience this time we used treatment type indicator variables. 

\begin{align*}
\mathsf{attacks}_i & \sim  \mathsf{NegativeBinomial}(\lambda_i, \phi_{\mathsf{userID[i]}} ) \\
log(\lambda_i) & =  l_{\mathsf{userID[i]}} +
                  a_{\mathsf{userID[i]}} * \mathsf{attacksL1} +
                  c_{\mathsf{userID[i]}} * \mathsf{act} + \\
                  & + 
      i1control_{\mathsf{userID[i]}} *  \mathsf{control} * \mathsf{intL1D}  + \\&         +  i1emp_{\mathsf{userID[i]}} *  \mathsf{emp} * \mathsf{intL1D}  + \\
      & +  i1norm_{\mathsf{userID[i]}} *  \mathsf{norm} * \mathsf{intL1D}
                   \\ 
  l_{\mathsf{userID[i]}} &  \sim \textsf{Norm}(\bar{l}, \bar{\sigma_l}) \\
  a_{\mathsf{userID[i]}} & \sim \textsf{Norm}(\bar{a}, \bar{\sigma_a}) \\
  c_{\mathsf{userID[i]}} & \sim \textsf{Norm}(\bar{c}, \bar{\sigma_c}) \\
  i1control_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(i1controlOverall,\bar{\sigma_{i1}}) \\
   i1emp_{\mathsf{userID[i]}} & \sim  \textsf{Norm}(i1empOverall, \bar{\sigma_{i1}})\\  
  i1norm_{\mathsf{userID[i]}}  & \sim  
    \textsf{Norm}(i1normOverall, \bar{\sigma_{i1}})\\
     i1controlOverall & \sim  \textsf{Norm}(0,.2)\\
    i1empOverall  & \sim  \textsf{Norm}(0,.2) \\
    i1normOverall  & \sim  \textsf{Norm}(0,.2) \\
    \bar{\lambda}  & \sim  \textsf{Norm}(.00001, 2.5) \\
    \bar{\sigma_l} & \sim  \mathsf{Exp}(1.5)\\
    \bar{a} & \sim \textsf{Norm}(0, .2) \\
    \bar{\sigma_a} & \sim  \mathsf{Exp}(5) \\
    \bar{c} & \sim  \mathsf{Norm}(0, .2)\\
    \bar{\sigma_c} & \sim \mathsf{Exp}(5) \\
    \bar{\sigma_{i1}} & \sim  \mathsf{Exp}(5)
\end{align*}



\footnotesize
```{r D1TSmodelFinal,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
d1full <-  ulam(
  alist(
    attacks ~ dgampois( lambda, phi),
    log(lambda) <- l[userID] + a[userID] * attacksL1 + c[userID] * act + 
      i1control[userID] *  control * intL1D  +
      i1emp[userID] *  emp * intL1D  +
      i1norm[userID] *  norm * intL1D,
    l[userID] ~ dnorm(lbar, lsigmabar),
    a[userID] ~ dnorm(abar, asigmabar),
    c[userID] ~ dnorm(cbar, csigmabar),
    i1control[userID] ~  dnorm(i1controlOverall, i1sigmabar),
    i1emp[userID] ~  dnorm(i1empOverall, i1sigmabar),
    i1norm[userID] ~  dnorm(i1normOverall, i1sigmabar),
    i1controlOverall ~ dnorm(0,.2),
    i1empOverall ~ dnorm(0,.2),
    i1normOverall ~ dnorm(0,.2),
    phi <- puser[userID],
    puser[userID] ~ dexp(pbar),
    lbar ~ dnorm(.00001, 2.5),
    lsigmabar ~ dexp(1.5),
    abar ~ dnorm(0, .2),
    asigmabar ~ dexp(5),
    cbar ~ dnorm(0, .2),
    csigmabar ~ dexp(5),
    i1sigmabar ~ dexp(5),
    pbar ~ dexp(5)   
  ), data=dat, log_lik = TRUE,
  chains = 2, iter = 8000,
  control = list(adapt_delta = 0.9), cores = 8)
```
\normalsize




This might seem somewhat confusing, so let us disentangle this maze:

\begin{itemize}
\item Each user has their own baseline aggression level, $l_{\mathsf{userID[i]}}$. \item However, these individual aggression levels are not disconnected, they come from a distribution themselves, $\textsf{Norm}(\bar{l}, \bar{\sigma_l})$. $\bar{l}$ is the mean baseline aggression level for the whole population, and $\bar{\sigma_l}$ is the standard deviation of this distribution. These general parameters are to be estimated along with the individual ones.
\item Then  there are individual auto regression coefficients     $a_{\mathsf{userID[i]}}$, which capture the correlation between  yesterday's attacks with today's attacks, so to speak. These also come from a general distribution $\textsf{Norm}(\bar{a}, \bar{\sigma_a})$, with its own general parameters to be estimated.
\item Next, there are individual user's coefficients connecting the user's activity on a given day with their aggression on the same day,  $c_{\mathsf{userID[i]}}$, all coming from a general distribution $\textsf{Norm}(\bar{c}, \bar{\sigma_c})$ whose parameters are also to be estimated.
\item For any particular treatment group, say, empathy, we have a user level coefficient $i1emp_{\mathsf{userID[i]}}$, which is activated if the user is in the empathy group (that is, we multiply by the indicator variable $\mathsf{emp}$) and then applied to the number of interventions received the day before (lag 1). Similarly for the two other groups. These user-level parameters come from the distribution $\textsf{Norm}(i1empOverall, \bar{\sigma_{i1}})$, whose parameters are to be estimated.
\item Finally, prior predictive check was used to choose priors for the general coefficients. 
\end{itemize}
As already mentioned, the coefficients need to be exponentiated to be understood multiplicatively.  For instance, the prior for $i1empOverall$ is $\textsf{Norm}(0,.2)$. To understand what priors for the exponentiated individual coefficients this entails, we can simulate: (1) draw 1e4 values $i1bar$ of the mean from  $\textsf{Norm}(0,.2)$,  (2) draw 1e4 values $i1sigmabar$  of the standard deviation parameter from $\mathsf{Exp(5)}$, and each time (3) draw 1e4 parameters from $\mathsf{Norm}(i1bar,i1sigmabar)$. The resulting distribution looks as in Figure \ref{fig:priori1plot}. This is still a very wide prior for the multiplicative impact of emphatetic interventions, centered around 1, allowing even extremely unlikely values close to 0 or 2 (upon reflection: you really should not expect a single intervention to reduce aggression to zero or to double it in everyone). In the cumulative model for computation reasons we will need to narrow down the distributions, but the general point hold: prior predictive check still ensures that they are centered around neutral values and that they allow for a very reasonable range of values. 

\footnotesize
```{r priori1,echo=TRUE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
set.seed(45)
i1bar <- rnorm(1e5,  0, .2)
i1sigmabar <- rexp(1e5, 5)
i1 <- rnorm(1e5, i1bar, i1sigmabar)
priorPlot2e <- ggplot()+geom_histogram(aes(x=exp(i1)), bins = 60)+xlim(0,2)+
  theme_tufte()

i3bar <- rnorm(1e5,  0, .1)
i3sigmabar <- rexp(1e5, 5)
i3 <- rnorm(1e5, i3bar, i3sigmabar)
priorPlot3e <- ggplot()+geom_histogram(aes(x=exp(i3)), bins = 60)+xlim(0,2)+
  theme_tufte()

```
\normalsize


\begin{figure}
```{r priori1plot,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
grid.arrange(priorPlot2e, priorPlot3e)
```
\caption{Simulated priors for the individual i1 coefficients, and prior for the cumulative impact model with larger input variability (hence, the prior is more narrow to eliminate unrealistically huge impact).}
\label{fig:priori1plot}
\end{figure}

For the impact of the cumulative number of interventions (we will only use lag 3 for reasons that will become clear), since the range of values of the predictor is wider, for computational feasibility we further needed to restrict coefficients to lie between -3 and 2, but these values are not plausible values of the parameters anyway ($exp(-3) \approx 0.04$ and $exp(2) \approx 7.38$). The model for the cumulative impact was tested with and without interaction with overall aggression in the before period, without the use of attacks on a given day (as already explained, to avoid the post-treatment bias). The two relevant lines in the models are:

\begin{align*}
log(\lambda_i) & =  l_{\mathsf{userID[i]}}  + c_{\mathsf{userID[i]}} \times \mathsf{act} + 
      ic3control_{\mathsf{userID[i]}} \times  \mathsf{control} \times \mathsf{intCL3D}  + \\ & + 
      ic3emp_{\mathsf{userID[i]}} \times  \mathsf{emp} \times \mathsf{intCL3D}  + \\ & 
      ic3norm_{\mathsf{userID[i]}} \times  \mathsf{norm} \times \mathsf{intCL3D}\\
log(\lambda_i) & =  l_{\mathsf{userID[i]}}  + c_{\mathsf{userID[i]}} \times  act + \\ & + 
      ic3control_{\mathsf{userID[i]}} \times   \mathsf{control} \times  \mathsf{intCL3D}  + \\ & + icabst3control_{\mathsf{userID[i]}} \times   \mathsf{control} \times  \mathsf{intCL3D} \times  \mathsf{abst} + \\ & 
      ic3emp_{\mathsf{userID[i]}} \times   \mathsf{emp} \times  \mathsf{intCL3D}  + \\ & + icabst3emp_{\mathsf{userID[i]}} \times   \mathsf{emp} \times  \mathsf{intCL3D}  \times  \mathsf{abst} + \\ & +
      ic3norm_{\mathsf{userID[i]}}] \times   \mathsf{norm} \times  \mathsf{intCL3D} + \\ & + icabst3norm_{\mathsf{userID[i]}} \times   \mathsf{norm} \times  \mathsf{intCL3D} \times  \mathsf{abst} 
\end{align*}

The models employing the second formula were superior in performance. It is not surprising that once attacks on a given day were removed from predictor, the overall aggression levels in the before period became predictive. The price to pay, however, is that now to obtain a user-specific multiplicative interpretation of the impact of cumulative interventions, we need to put the two elements together while multiplying one by the user's overall aggression and only then exponentiate, that is we need to inspect, for instance, $exp(ic3emp_{\mathsf{userID[i]}}  +  icabst3emp_{\mathsf{userID[i]}} \times \mathsf{abst}[i])$,
instead of simply looking at $exp(ic3emp_{\mathsf{userID[i]}})$. 


\footnotesize
```{r rstanCumupative,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
#RStan model code for cumulative interventions lag 3
data{
  int<lower=0> N;
  int<lower=0> U;
  vector[N] abst;
  int interventions[N];
  int type[N];
  int intCL1D[N];
  int intCL2D[N];
  int intCL3D[N];
  int intCL4D[N];
  int intCL5D[N];
  int intCL6D[N];
  int intCL7D[N];
  int intL1D[N];
  int intL2D[N];
  int intL3D[N];
  int intL4D[N];
  int intL5D[N];
  int intL6D[N];
  int intL7D[N];
  int attacksL1[N];
  int attacksL2[N];
  int attacksL3[N];
  int attacksL4[N];
  int attacksL5[N];
  int attacksL6[N];
  int attacksL7[N];
  int weekday[N];
  int attacks[N];
  int norm[N];
  int emp[N];
  int control[N];
  int act[N];
  int userID[N];
}
parameters{
  vector<lower = -80>[U] l;
  vector<lower=-3,upper=2>[U] c;
  vector<lower=-3,upper=2>[U] ic3control;
  vector<lower=-3,upper=2>[U] icabst3control;
  vector<lower=-3,upper=2>[U] ic3emp;
  vector<lower=-3,upper=2>[U] icabst3emp;
  vector<lower=-3,upper=2>[U] ic3norm;
  vector<lower=-3,upper=2>[U] icabst3norm;
  real<lower=-3,upper=2> ic3controlOverall;
  real<lower=-3,upper=2> ic3empOverall;
  real<lower=-3,upper=2> ic3normOverall;
  real<lower=-3,upper=2> icabst3controlOverall;
  real<lower=-3,upper=2> icabst3empOverall;
  real<lower=-3,upper=2> icabst3normOverall;
  vector<lower=0>[U] puser;
  real<lower = -3, upper = 2> lbar;
  real<lower=0> lsigmabar;
  real<lower = -3, upper = 2> cbar;
  real<lower=0> csigmabar;
  real<lower=0> ic3sigmabar;
  real<lower=0> icabst3sigmabar;
  real<lower=0> pbar;
}
model{
  vector[N] lambda;
  vector[N] phi;
  pbar ~ exponential( 5 );
  icabst3sigmabar ~ exponential( 25 );
  ic3sigmabar ~ exponential( 25 );
  csigmabar ~ exponential( 5 );
  cbar ~ normal( 0.1 , 0.1 );
  lsigmabar ~ exponential( 0.5 );
  lbar ~ normal( 0 , 0.5 );
  puser ~ exponential( pbar );
  for ( i in 1:N ) {
    phi[i] = puser[userID[i]];
  }
  icabst3normOverall ~ normal( 0 , 0.1 );
  icabst3empOverall ~ normal( 0 , 0.1 );
  icabst3controlOverall ~ normal( 0 , 0.1 );
  ic3normOverall ~ normal( 0 , 0.1 );
  ic3empOverall ~ normal( 0 , 0.1 );
  ic3controlOverall ~ normal( 0 , 0.1 );
  icabst3norm ~ normal( icabst3normOverall , icabst3sigmabar );
  ic3norm ~ normal( ic3normOverall , ic3sigmabar );
  icabst3emp ~ normal( icabst3empOverall , icabst3sigmabar );
  ic3emp ~ normal( ic3empOverall , ic3sigmabar );
  icabst3control ~ normal( icabst3controlOverall , icabst3sigmabar );
  ic3control ~ normal( ic3controlOverall , ic3sigmabar );
  c ~ normal( cbar , csigmabar );
  l ~ normal( lbar , lsigmabar );
  for ( i in 1:N ) {
    lambda[i] = l[userID[i]] + c[userID[i]] * act[i] +
      ic3control[userID[i]] * control[i] * intCL3D[i] +
      icabst3control[userID[i]] * control[i] * intCL3D[i] * abst[i] +
      ic3emp[userID[i]] * emp[i] * intCL3D[i] + 
      icabst3emp[userID[i]] * emp[i] * intCL3D[i] * abst[i] +
      ic3norm[userID[i]] * norm[i] * intCL3D[i] + 
      icabst3norm[userID[i]] * norm[i] * intCL3D[i] * abst[i];
    lambda[i] = exp(lambda[i]);
  }
  attacks ~ neg_binomial_2( lambda , phi );
}
generated quantities{
  vector[N] log_lik;
  vector[N] lambda;
  vector[N] phi;
  for ( i in 1:N ) {
    phi[i] = puser[userID[i]];
  }
  for ( i in 1:N ) {
    lambda[i] = l[userID[i]] + c[userID[i]] * act[i] + 
      ic3control[userID[i]] * control[i] * intCL3D[i] + 
      icabst3control[userID[i]] * control[i] * intCL3D[i] * abst[i] +
      ic3emp[userID[i]] * emp[i] * intCL3D[i] + 
      icabst3emp[userID[i]] * emp[i] * intCL3D[i] * abst[i] + 
      ic3norm[userID[i]] * norm[i] * intCL3D[i] +
      icabst3norm[userID[i]] * norm[i] * intCL3D[i] * abst[i];
    lambda[i] = exp(lambda[i]);
  }
  for ( i in 1:N ) log_lik[i] = neg_binomial_2_lpmf( attacks[i] | lambda[i] , phi[i] );
}
```
\normalsize


Finally, in the before-and-after analysis, we put aside the time series element, look at aggregated counts before and after the treatment period, thus obtaining a more of a long-term effect analysis. Moreover, this time we standardize counts, obtaining continuous variables and employing normal distribution in the likelihoods, thus also making sure the overall results are robust under a spectrum of modeling choices.  We build and compared  multiple additive models where the outcome variable is normally distributed around the predicted mean, which is a linear function of predictors (possibly with  interactions). Bayesian information criteria  (WAIC)  applied to a wide selection of predictors lead to the model, whose specification is as follows (we also selected regularizing prior parameters using prior predictive checks to avoid unreasonably narrow overall prior distributions):


\vspace{-8mm}

\begin{align*}
\mathsf{AdiffS} & \sim \textsf{Norm}(\mu, \sigma)\\
\mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} + \beta_{\mathsf{group}_i}  +
 \beta_{\mathsf{IC}}[\mathsf{group}_i]\times \mathsf{IC} + \\
 & + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC} + \beta_{\mathsf{CBS}}[\mathsf{group}_i] \times \mathsf{CBS}\\
 \alpha & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{ADS}}[\mathsf{group}_i] & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{group}_i} & \sim \textsf{Norm}(0,.3)\\
\beta_{\mathsf{IC}}[\mathsf{group}_i] & \sim \textsf{Norm}(0,.3)\\
 \beta_{\mathsf{ADSIC}} & \sim \textsf{Norm}(0,.3)\\
 \beta_{\mathsf{CBS}}[\mathsf{group}_i]& \sim \textsf{Norm}(0,.3)\\
\end{align*}


\vspace{-9mm}

That is, we take the resulting mean to be the result of the general average ($\alpha$) and the impact of the following coefficients: group-specific coefficient for \textsf{ADS}, group coefficient, group-specific coefficient for \textsf{IC}, interaction coefficient for \textsf{ADS} and \textsf{IC}, and group-specific coefficient for \textsf{CBS}. This is plausible \emph{prima facie}, as which group a user belongs to might have impact on  how the number of attacks during the treatment are related to  the number of attacks after, the role  of the intervention count, and the role of comments before. Moreover, the levels of aggressive behavior displayed by the user during treatment might have impact on the role played by the intervention count. 

Now, let's build two models with this general structure, one with fairly wide priors that one might initially think are appropriate, one with regularizing priors. The key phenomenon to watch out for in such contexts (slightly complex models with interactions) is that it is hard to intuitively predict the impact of coefficient priors on prior predictions. For this reason, we run prior predictive checks for both models. 


\footnotesize 
```{r priorModels,echo=TRUE,eval=FALSE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
# building model with sd=1
InteractionsModelDiffSD1 <- ulam(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC+
    bADSIC * ADS * IC+ bCBS[groupID] *CBS,
    a ~ dnorm (0,1),
    bADS[groupID] ~ dnorm(0,1),
    bADSIC ~ dnorm(0,1),
    bCBS[groupID] ~ dnorm(0,1),
    bIT[groupID] ~ dnorm(0,1),
    bIC[groupID] ~ dnorm(0,1),
    sigma  ~ dexp(1)
  ),
  data = summaries
 )

#now model with prior sd = .3
InteractionsModelDiff <- ulam(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
    bADSIC * ADS * IC+ bCBS[groupID] *CBS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)
```




\vspace{1mm}
\footnotesize
```{r priorModels2,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
InteractionsModelDiffSD1 <- readRDS(file = "models/InteractionsModelDiffSD1.rds")
InteractionsModelDiff <- readRDS(file = "models/InteractionsModelDiff.rds")

#prior predictive checks sd =1
ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 5  #mean for interventions in treatment
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
#prior <- extract.prior(InteractionsModelDiffSD1, n = 1e4)
#saveRDS(prior, file = "datasets/prior1.RDS")
prior <- readRDS(file = "datasets/prior1.RDS")
mu <- link( InteractionsModelDiffSD1 , post=prior , data=data )
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")

priorGroupsSD1 <- ggplot(muLong)+
  geom_violin(aes(x = group, color = group, y = AdiffS))+
  theme_tufte()+xlab("")+
  labs(title = "Simulated priors by group",
  subtitle = "(at ADS = CBS = 0, IC at mean = 5, sd = 1)")+
  scale_color_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
  guides(color = "none")+
  ylab("change in attacks (standardized)")+theme(plot.title.position = "plot")

ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 0:20
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
#prior <- extract.prior(InteractionsModelDiffSD1, n = 1e4)
#saveRDS(prior, file = "datasets/prior2.RDS")
prior <- readRDS(file = "datasets/prior2.RDS")
mu <- link(InteractionsModelDiffSD1 , post=prior , data=data )
mu.mean <- apply( mu , 2, mean )
mu.HPDI <- data.frame(t(apply( mu , 2 , HPDI )))
priorDF <- cbind(data, mu.mean, mu.HPDI)
priorDF$groupID <- as.factor(groupID)
levels(priorDF$groupID) <- c("control", "empathy", "normative")
colnames(priorDF)[2]<- "group"


priorICSD1  <- ggplot(priorDF, aes(x = IC, y  = mu.mean,  fill = group))+
  geom_line()+geom_ribbon(aes(ymin = X.0.89, ymax = X0.89.), alpha = 0.2)+
  theme_tufte()+ylab("change in attacks (standardized)")+
  labs(title = "Simulated priors for AAS vs IC",
      subtitle = "(at ADS = CBS = 0, sd = 1)")+xlab("interventions")+
  scale_fill_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
  theme(plot.title.position = "plot")


priorJoint1 <- ggarrange(priorGroupsSD1,priorICSD1, ncol = 2)
priorJoint1Titled <- annotate_figure(priorJoint1,
  top = text_grob("Predictive priors with sd=1 are insanely wide",
                  size = 14))

#Some experimentation leads to the value of $\sigma =.3$, which leads to the following priors:
#prior predictive check sd =.3
ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 5  #mean for interventions in treatment
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
#prior <- extract.prior(InteractionsModelDiff, n = 1e4)
#saveRDS(prior, file = "datasets/prior3.RDS")
prior <- readRDS(file = "datasets/prior3.RDS")

mu <- link(InteractionsModelDiff , post=prior , data=data ) 
colnames(mu) <- levels(summaries$group)
muLong <- melt(mu)
colnames(muLong) <- c("id", "group", "AdiffS")


priorGroupSD03 <- ggplot(muLong)+
  geom_violin(aes(x = group, color = group, y = AdiffS))+theme_tufte()+
  xlab("")+
  labs(title = "Simulated priors  by group", 
  subtitle = "(at ADS = CBS = 0, IC at mean = 5, sd = .3)")+
  ylab("change in attacks (standarized)")+
  scale_color_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
  guides(color = "none")+
  theme(plot.title.position = "plot")


ADS <- 0
CBS <- 0
groupID <- 1:3
IC <- 0:20
data <- expand.grid(ADS = ADS,groupID = groupID, CBS = CBS, IC =  IC)
#prior <- extract.prior(InteractionsModelDiff, n = 1e4)
#saveRDS(prior, file = "datasets/prior4.RDS")
prior <- readRDS(file = "datasets/prior4.RDS")
mu <- link(InteractionsModelDiff , post=prior , data=data )
mu.mean <- apply( mu , 2, mean )
mu.HPDI <- data.frame(t(apply( mu , 2 , HPDI )))
priorDF <- cbind(data, mu.mean, mu.HPDI)
priorDF$groupID <- as.factor(groupID)
levels(priorDF$groupID) <- c("control", "empathy", "normative")
colnames(priorDF)[2]<- "group"


priorICSD03  <- ggplot(priorDF, aes(x = IC, y  = mu.mean,  fill = group))+
  geom_line()+geom_ribbon(aes(ymin = X.0.89, ymax = X0.89.), alpha = 0.2)+
  theme_tufte()+ylab("change in attacks (standardized)")+
  scale_fill_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
  labs(title = "Simulated priors for AAS vs IC",
      subtitle = "(at ADS = CBS = 0, sd = .3)")+xlab("interventions")


priorJoint03 <- ggarrange(priorGroupSD03,priorICSD03, ncol = 2) 
priorJoint03Titled <- annotate_figure(priorJoint03, 
  top = text_grob("Predictive priors with sd=.3 seem sensible",
                  size = 14))
#priorJoint03Titled
```
\normalsize


\begin{figure}[H]
```{r fig:priorCheck,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "80%",   message = FALSE, warning = FALSE, results = FALSE}
priorJoint1Titled
priorJoint03Titled
```

\caption{Prior predictive check for two different sets of priors.}
\label{fig:priors}
\end{figure}



Now,  let's double-check if our model building tools behave appropriately for models of this sort on the data that we have---some model diagnostics before we move on (Figure \ref{fig:traceplot}). What we are witnessing is (1) stationarity (the chains stay mostly in the most probable regions), (2) good mixing (they explore a range of options in the beginning), and (3) convergence (they stabilize as they progress).  We also need to   inspect the distribution of residuals, expecting them to be more or less normally distributed, which they are (Figure \ref{fig:residuals}).


\begin{figure}
```{r traceplot,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "80%", results = "hide"}
InteractionsModelDiff <- readRDS(file = "models/InteractionsModelDiff.rds")
traceplot( InteractionsModelDiff )
```
\caption{Traceplot of the model selected using Widelly Acceptable Information Criterion.}
\label{fig:traceplot}
\end{figure}



\begin{figure}[H]
```{r residualsPlot,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "60%", results = "hide"}
mu <- link(InteractionsModelDiff)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- summaries$AdiffS - mu_mean
ggplot()+geom_density(aes(x = mu_resid))+theme_tufte()+ theme(plot.title.position = "plot", plot.title = element_text(size=15)) +
  ggtitle("Residuals are approximately normally distributed")+xlab("residuals")
```
\caption{Distribution of residuals from the selected model.}
\label{fig:residuals}
\end{figure}



Now, let us elaborate on how  we decided to use  to this seemingly fairly complicated model. Once preliminary causal considerations guided our restrictions on variable selection, we proceed by building models of increasing complexity, and comparing them in terms of Widely Acceptable Information Criterion (which we have already discussed). The models differ mostly in the underlying linear formulae. For computational ease we will here use quadratic approximations, while in the final analysis we will deploy Hamiltionian Monte Carlo. The names are meant to decode the model structure: the predictors are listed before dashes, whereas interactions are listed after dashes. The comparison results are in Table \ref{tab:comparison} and plotted in Figure \ref{fig:modelComparisonPlot}. Notice that there are ways of building a complicated models that do not result in improvement, as they rather lead to expected performance lower than that of the null model. 

\begin{align}
\tag{Null}  \mu_i & = \alpha\\
\tag{ADS}  \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS}\\
\tag{ADSIC}  \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS} +    \beta_{\mathsf{IC}}\times \mathsf{IC}\\
\tag{IT}  \mu_i & = \beta_{\mathsf{group}[i]} \\
\tag{ADSIT} \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS} +  \beta_{\mathsf{group}[i]}\\
\tag{ADSITIC} \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS} +  \beta_{\mathsf{group}[i]} +    \beta_{\mathsf{IC}}\times \mathsf{IC}\\
\tag{ADSITIC-ADSIC} \mu_i & = \alpha + \beta_{\mathsf{ADS}}\times \mathsf{ADS} +  \beta_{\mathsf{group}[i]} +    \beta_{\mathsf{IC}}\times \mathsf{IC} + \\ & + \nonumber \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC}\\
\tag{ADSITIC-ADSIC-ADSIT} \mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} +  \beta_{\mathsf{group}[i]} +  \\ \nonumber & +  \beta_{\mathsf{IC}}\times \mathsf{IC} + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC}\\
\tag{ADSIT-ADSIT}   \mu_i &  = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i] \times
 \mathsf{ADS} + \beta_{\mathsf{group}[i]} \\
\tag{ADSITIC-ADSIT-ITIC-ADSIC}   \mu_i &  = \alpha  +  \beta_{\mathsf{ADS}}[\mathsf{group}_i] \times \mathsf{ADS} + \beta_{\mathsf{group}[i]} +  \\ & + 
\beta_{\mathsf{IC}}[\mathsf{group}_i] \times \mathsf{IC}   \nonumber  + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC}\\
\tag{ADSITICCBS-ITIC-ADSIC} \mu_i &  = \alpha  +  \beta_{\mathsf{ADS}}[\mathsf{group}_i] \times
 \mathsf{ADS}  + \beta_{\mathsf{group}[i]} + \\ & +    \beta_{\mathsf{IC}}[\mathsf{group}_i] \times \mathsf{IC}  \nonumber  + \beta_{\mathsf{CBS}} \times \mathsf{CBS} +  \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC}  \\
\tag{Final} \mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} + \beta_{\mathsf{group}_i}  +  \beta_{\mathsf{IC}}[\mathsf{group}_i]\times \mathsf{IC} + \\
 & + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC} + \beta_{\mathsf{CBS}}[\mathsf{group}_i] \times \mathsf{CBS} \nonumber\\
 \tag{tooFar} \mu_i & = \alpha + \beta_{\mathsf{ADS}}[\mathsf{group}_i]\times \mathsf{ADS} + \beta_{\mathsf{group}_i}  +  \beta_{\mathsf{IC}}[\mathsf{group}_i]\times \mathsf{IC} + \\
 & + \beta_{\mathsf{ADSIC}}\times \mathsf{ADS} \times \mathsf{IC} + \beta_{\mathsf{CBS}}[\mathsf{group}_i] \times \mathsf{CBS} + \beta_{\mathsf{CBSIC}}\times
 \mathsf{CBS} \times \mathsf{IC} \nonumber \end{align}




\vspace{1mm}
\footnotesize
```{r modelSelection1,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
null <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu ~ dnorm (0,0.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)

ADS <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  a + bADS * ADS,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)

ADSIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  a + bADS * ADS+ bIC * IC,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,0.3),
    bIC ~ dnorm(0,0.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


IT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <-  bIT[groupID] ,
    bIT[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


ADSIT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID],
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


ADSITIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID] + bIC * IC,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


ADSITIC_ADSIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS * ADS +  bIT[groupID] + bIC * IC + bADSIC * ADS * IC,
    a ~ dnorm (0,0.3),
    bADS ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


ADSITIC_ADSIC_ADSIT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC * IC + bADSIC * ADS * IC,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


ADSIT_ADSIT <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] ,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    #bADSIC ~ dnorm(0,.5),
    bIT[groupID] ~ dnorm(0,.3),
    #bIC ~ dnorm(0,.5),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


ADSITIC_ADSIT_ITIC_ADSIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
      bADSIC * ADS * IC,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


ADSITICCBS_ITIC_ADSIC <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
      bADSIC * ADS * IC+ bCBS *CBS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)


Final <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
      bADSIC * ADS * IC+ bCBS[groupID] *CBS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)



tooFar <- quap(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] + bIC[groupID] * IC +
      bADSIC * ADS * IC+ bCBS[groupID] *CBS + bCBSIC * CBS * IC,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
     bCBSIC ~ dnorm(0, .3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)

```
\normalsize










\vspace{1mm}
\footnotesize
```{r buildComparisons,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
comparison<- compare(null,ADS,ADSIC,IT,ADSIT,ADSITIC,ADSITIC_ADSIC,
                     ADSITIC_ADSIC_ADSIT,ADSIT_ADSIT,ADSITIC_ADSIT_ITIC_ADSIC,
                     ADSITICCBS_ITIC_ADSIC,Final, tooFar)
```


<!-- ```{r comparisonsTable,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"} -->
<!-- kable(round(data.frame(comparison ),3), "latex", booktabs = T,linesep = "") %>% kable_styling(latex_options = "striped",font_size = 9)   -->
<!-- ``` -->

\begin{table}
\centering\begingroup\fontsize{9}{11}\selectfont
\begin{tabular}{lrrrrrr}
\toprule
  & WAIC & SE & dWAIC & dSE & pWAIC & weight\\
\midrule
\cellcolor{gray!6}{Final} & \cellcolor{gray!6}{1184.829} & \cellcolor{gray!6}{89.779} & \cellcolor{gray!6}{0.000} & \cellcolor{gray!6}{NA} & \cellcolor{gray!6}{26.871} & \cellcolor{gray!6}{0.590}\\
tooFar & 1186.126 & 89.413 & 1.297 & 2.758 & 28.181 & 0.308\\
\cellcolor{gray!6}{ADSITICCBS\_ITIC\_ADSIC} & \cellcolor{gray!6}{1188.337} & \cellcolor{gray!6}{87.058} & \cellcolor{gray!6}{3.508} & \cellcolor{gray!6}{6.184} & \cellcolor{gray!6}{24.822} & \cellcolor{gray!6}{0.102}\\
IT & 1345.087 & 144.443 & 160.259 & 132.802 & 18.104 & 0.000\\
\cellcolor{gray!6}{null} & \cellcolor{gray!6}{1345.550} & \cellcolor{gray!6}{145.960} & \cellcolor{gray!6}{160.721} & \cellcolor{gray!6}{134.243} & \cellcolor{gray!6}{18.616} & \cellcolor{gray!6}{0.000}\\
ADS & 1348.696 & 143.821 & 163.867 & 132.558 & 22.718 & 0.000\\
\cellcolor{gray!6}{ADSITIC\_ADSIC} & \cellcolor{gray!6}{1351.556} & \cellcolor{gray!6}{152.861} & \cellcolor{gray!6}{166.728} & \cellcolor{gray!6}{139.154} & \cellcolor{gray!6}{29.070} & \cellcolor{gray!6}{0.000}\\
ADSIT & 1351.646 & 145.161 & 166.817 & 133.795 & 25.032 & 0.000\\
\cellcolor{gray!6}{ADSITIC} & \cellcolor{gray!6}{1352.087} & \cellcolor{gray!6}{146.835} & \cellcolor{gray!6}{167.258} & \cellcolor{gray!6}{134.608} & \cellcolor{gray!6}{27.254} & \cellcolor{gray!6}{0.000}\\
ADSIT\_ADSIT & 1352.672 & 155.862 & 167.844 & 142.092 & 31.855 & 0.000\\
\cellcolor{gray!6}{ADSIC} & \cellcolor{gray!6}{1352.892} & \cellcolor{gray!6}{146.359} & \cellcolor{gray!6}{168.064} & \cellcolor{gray!6}{134.313} & \cellcolor{gray!6}{26.421} & \cellcolor{gray!6}{0.000}\\
ADSITIC\_ADSIC\_ADSIT & 1355.482 & 155.522 & 170.653 & 141.405 & 33.558 & 0.000\\
\cellcolor{gray!6}{ADSITIC\_ADSIT\_ITIC\_ADSIC} & \cellcolor{gray!6}{1355.783} & \cellcolor{gray!6}{155.273} & \cellcolor{gray!6}{170.954} & \cellcolor{gray!6}{141.128} & \cellcolor{gray!6}{33.771} & \cellcolor{gray!6}{0.000}\\
\bottomrule
\end{tabular}
\endgroup{}
\caption{Model comparison results.}
\label{tab:comparison}
\end{table}





\begin{figure}[H]
```{r fig:modelComparison,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
plot(comparison)
```
\caption{Model comparison, WAIC scores. The filled points are the in-sample deviance values. The open points are the WAIC values. The line segments represent standard errors of the WAIC scores. really want however is the standard error of the difference in WAIC
between the two models. The triangle is the difference to the top rated model, and the line segment going through it is the standard error of this difference.}
\label{fig:modelComparisonPlot}
\end{figure}

\normalsize 
  The three models that stand out  differ in including $\mathsf{CBS}$ as a predictor.  Moreover the final model includes an interaction between  treatment group and $\mathsf{CBS}$. Adding a further interaction between $\mathsf{CBS}$ and $\mathsf{IC}$ takes us too far. We will employ the top model ($\mathsf{Final}$) in   further analyses. 
  

Now that we have explained how and why our models were built and selected, we move on to the presentation of the results.


# Results

## Interventions on a given day


We build seven separate models for the impact of interventions $k$ days ago, $1\leq k \leq 7$. In Figure \ref{fig:dailyResults} we visualize the results for the three groups, with  jitter based on user aggression in the before period. 


\footnotesize
```{r dailyResults,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}

hateDFs <- readRDS(file ="datasets/hateDFs2.RDS")
sampleDFs <- hateDFs

d1precis <- readRDS("timeSeriesDFs/d1precis.rds")
d2precis <- readRDS("timeSeriesDFs/d2precis.rds")
d3precis <- readRDS("timeSeriesDFs/d3precis.rds")
d4precis <- readRDS("timeSeriesDFs/d4precis.rds")
d5precis <- readRDS("timeSeriesDFs/d5precis.rds")
d6precis <- readRDS("timeSeriesDFs/d6precis.rds")
d7precis <- readRDS("timeSeriesDFs/d7precis.rds")

n <- length(hateDFs)
df <- list()
dfCleanList <- list()

dfextract <- function(precis, day){
  df[[day]] <- precis
  df[[day]] <- df[[day]][grep(paste("^i",day, sep = ""), rownames(df[[day]])),]
  df[[day]] <- df[[day]][- grep(paste("i",day,"sigmabar", sep = ""),
                                rownames(df[[day]])),]
  df[[day]]$day <- rep(day, nrow(df[[day]]))
  df[[day]]$expMean <- exp(df[[day]]$mean)
  df[[day]]$expLow <- exp(df[[day]]$`5.5%`)
  df[[day]]$expHigh <- exp(df[[day]]$`94.5%`)
  df[[day]]$expHigh <- ifelse( df[[day]]$expHigh <2, df[[day]]$expHigh, 2)
  
  df[[day]]$type <- as.factor(c(rep("control", n), rep("empathy", n),
                    rep("normative", n), c("control", "empathy", "normative")))
  abs <- numeric(3 * n +3)
  for(i in 1:n){
    abs[i] <- sampleDFs[[i]]$ABS[1]
  }
  abs <- c(abs[1:n],abs[1:n],abs[1:n], rep(NA,3))
  df[[day]]$abs <- abs
  
  dfc <- df[[day]][1:n,]
  dfe <- df[[day]][(n+1): (n+n),]
  dfn <- df[[day]][ ((2 *n)+1): ((2 *n) +n),]
  
  control <- numeric(n)
  emp <- numeric(n)
  norm <- numeric(n)
  for(i in 1:n){
    control[i] <- sampleDFs[[i]]$type[1] == "control"
    emp[i] <- sampleDFs[[i]]$type[1] == "emp"
    norm[i] <- sampleDFs[[i]]$type[1] == "norm"
  }
  
  dfClean <- rbind(dfc[control == TRUE,],dfe[emp == TRUE,],dfn[norm == TRUE,],
                   tail(df[[day]],3))

  return(dfClean)
}

dfCleanList[[1]] <-  dfextract(d1precis, day = 1)    
dfCleanList[[2]] <-  dfextract(d2precis, day = 2) 
dfCleanList[[3]] <-  dfextract(d3precis, day = 3)   
dfCleanList[[4]] <-  dfextract(d4precis, day = 4)
dfCleanList[[5]] <-  dfextract(d5precis, day = 5)
dfCleanList[[6]] <-  dfextract(d6precis, day = 6) 
dfCleanList[[7]] <-  dfextract(d7precis, day = 7)    
dfVis <- do.call(rbind, dfCleanList)

dfVisInd <- dfVis[!is.na(dfVis$abs),]
dfVisOv <- dfVis[is.na(dfVis$abs),]
dfVisInd$dayDF <- (dfVisInd$day * 5) - 5
dfVisOv$dayDF <- (dfVisOv$day * 5) - 5

daysPlot2 <- ggplot(dfVisInd)+theme_tufte()+
  labs(title = "Multiplicative impact of a single past intervention",
       subtitle  = "(with 89% posterior density intervals)", x = "days ago", 
       y = "multiplier")+
  scale_x_continuous(breaks = seq(0,30, by = 5), 
        labels = seq(1,7), limits = c(-.5,30))+ ylim(c(0.5,1.5))+
  facet_wrap(~type, ncol = 1)+
  geom_hline(aes(yintercept = 1), color = "gray", alpha = 0.7, lty =2, size =.5)+
  geom_pointrange(aes(x = dayDF + 0.4 * abs, y  = expMean, 
        color = abs, ymin = expLow, ymax = expHigh ), alpha = .2, size = .05)+
  geom_pointrange(data = dfVisOv, aes(x = dayDF -.4 , y  = expMean,
            ymin = expLow, ymax = expHigh), size = .3)+
  theme(plot.title.position = "plot",legend.position = "bottom")+
  geom_label_repel(data = dfVisOv, aes(x = dayDF -.4 , y  = expMean,
            label = round(expMean,2)), size = 2, box.padding = .8,
            label.padding = .15,label.size = .2,label.r = 0.2)

```
  
  
  


\begin{figure}[H]
```{r fig:dailyResultsPlot,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
daysPlot2
```
\caption{Impact of interventions received lag $1\leq k \leq 7$ on attacks on a given day. High-level coefficients are pictured in black.}
\label{fig:dailyResults}
\end{figure}
  
  \normalsize 
  
Notice that in short term, interventions actually increase aggression the next day (even taking the user's yesterday's aggression and today's activity in consideration). The effect, however, quickly wears off. 


## Cumulative sum of interventions


In our analysis of the effect of the cumulative number of interventions received so far, however, we intend separate this short-term effect from the long-term effect. To achieve this, we lag the cumulative interventions variable by 3, so that we're giving the user the minimal number of days needed for the short-term effect to wane. The individual users' multiplicative impact coefficients are visualized in Figure \ref{fig:cumulativeResultsPlot}.




\footnotesize
```{r cumulativeResults,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
getPrecisForParamOv <- function(object, i, group){
  samples <- as.data.frame(object[[i]])
  means <- as.data.frame(sapply(samples, mean))
  hpdis <- as.data.frame(t(sapply(samples, HPDI)))
  df <- cbind(means, hpdis)
  colnames(df) <- c("mean", "low", "high")
  df$param <- rep(names(object[i]), nrow(df))
  df$expMean <- exp(df$mean)
  df$expLow <- exp(df$low)
  df$expHigh <- exp(df$high)
  df$group <- rep(group, nrow(df))
  rownames(df) <- df$param
  return(df)
}


getPrecisForParamInd <- function(object, i, group, dat){
#  object <- samplesA; i <- 10; group = "A"; dat  = datA
  samples <- as.data.frame(object[[i]])
  head(samples)
  means <- as.data.frame(sapply(samples, mean))
  hpdis <- as.data.frame(t(sapply(samples, HPDI)))
  df <- cbind(means, hpdis)
  colnames(df) <- c("mean", "low", "high")
  df$expMean <- exp(df$mean)
  df$expLow <- exp(df$low)
  df$expHigh <- exp(df$high)
  df$user <- paste(group, "user",1:nrow(df), sep = "")
  df$userID <- 1:nrow(df)
  head(df)
  for (id in 1:nrow(df)){
  df$type[id] <- dat$type[dat$userID == id][1]
  }
  for(u in 1:nrow(df)){
    df$abst[u] <-   datA$abst[dat$user == u][1]
  }
  df$group <- rep(group, nrow(df))
  df$param <- rep(names(object[i]), nrow(df))
  df$paramType <- rep(0,nrow(df))
  df$paramType[grep("control",df$param)] <- 1 
  df$paramType[grep("emp",df$param)] <- 2 
  df$paramType[grep("norm",df$param)] <- 3
  df <- df[df$type == df$paramType,]
  return(df)
}

datA <- readRDS(file = "timeSeries/tsaStanCumulative/datA.RDS")
fitA <- readRDS("timeSeries/tsaStanCumulative/c3interactionStanFitA.rds")
datB <- readRDS(file = "timeSeries/tsaStanCumulative/datB.RDS")
fitB <- readRDS("timeSeries/tsaStanCumulative/c3interactionStanFitB.rds")
datC <- readRDS(file = "timeSeries/tsaStanCumulative/datC.RDS")
fitC <- readRDS("timeSeries/tsaStanCumulative/c3interactionStanFitC.rds")
datD <- readRDS(file = "timeSeries/tsaStanCumulative/datD.RDS")
fitD <- readRDS("timeSeries/tsaStanCumulative/c3interactionStanFitD.rds")

samplesA <- rstan::extract(fitA, permuted = TRUE,
                           inc_warmup = FALSE,  include = TRUE)
samplesB <- rstan::extract(fitB, permuted = TRUE,
                           inc_warmup = FALSE,  include = TRUE)
samplesC <- rstan::extract(fitC, permuted = TRUE,
                           inc_warmup = FALSE,  include = TRUE)
samplesD <- rstan::extract(fitD, permuted = TRUE,
                           inc_warmup = FALSE,  include = TRUE)

paramsIndividualIndices <- c(1,2,3,10,11,12)
paramsOverallIndices <- 4:9

precisAind <- list()
for (i in 1:6){
  precisAind[[i]] <- getPrecisForParamInd(samplesA, 
                     paramsIndividualIndices[i], "A", datA)
}
names(precisAind) <- names(samplesA)[c(1,2,3,10,11,12)]

precisAov <- list()
for (i in 1:6){
  precisAov[[i]] <- getPrecisForParamOv(samplesA,
                    paramsOverallIndices[i], "A")
}
names(precisAov) <- names(samplesA)[4:9]

#B
precisBind <- list()
for (i in 1:6){
  precisBind[[i]] <- getPrecisForParamInd(samplesB, 
                     paramsIndividualIndices[i], "B", datB)
}
names(precisBind) <- names(samplesB)[c(1,2,3,10,11,12)]

precisBov <- list()
for (i in 1:6){
  precisBov[[i]] <- getPrecisForParamOv(samplesB, 
                    paramsOverallIndices[i], "B")
}
names(precisBov) <- names(samplesB)[4:9]

#C
precisCind <- list()
for (i in 1:6){
  precisCind[[i]] <- getPrecisForParamInd(samplesC,
                    paramsIndividualIndices[i], "C", datC)
}
names(precisCind) <- names(samplesC)[c(1,2,3,10,11,12)]

precisCov <- list()
for (i in 1:6){
  precisCov[[i]] <- getPrecisForParamOv(samplesC, 
                    paramsOverallIndices[i], "C")
}
names(precisCov) <- names(samplesC)[4:9]

#D
precisDind <- list()
for (i in 1:6){
  precisDind[[i]] <- getPrecisForParamInd(samplesD, 
                     paramsIndividualIndices[i], "D", datD)
}
names(precisDind) <- names(samplesD)[c(1,2,3,10,11,12)]

precisDov <- list()
for (i in 1:6){
  precisDov[[i]] <- getPrecisForParamOv(samplesD, 
                    paramsOverallIndices[i], "D")
}
names(precisDov) <- names(samplesD)[4:9]

dfVisIndA <- do.call(rbind, precisAind)
dfVisIndB <- do.call(rbind, precisBind)
dfVisIndC <- do.call(rbind, precisCind)
dfVisIndD <- do.call(rbind, precisDind)
dfVisInd <- rbind(dfVisIndA,dfVisIndB,dfVisIndC, dfVisIndD)


dfVisOvA <-  do.call(rbind, precisAov)
dfVisOvB <-  do.call(rbind, precisBov)
dfVisOvC <-  do.call(rbind, precisCov)
dfVisOvD <-  do.call(rbind, precisDov)
dfVisOv <- rbind(dfVisOvA,dfVisOvB,dfVisOvC,dfVisOvD )


abstBaseline <- seq(-1,1.5, by = .01)
groups <- c("A", "B", "C", "D")
groupedPredictions <- list()

for(i in 1:4){
groupDF <- subset(dfVisOv, group == groups[i])
groupControlLow <- exp(groupDF$low[1] + groupDF$low[6] * abstBaseline) 
groupControlHigh <- exp(groupDF$high[1] + groupDF$high[6] * abstBaseline) 
groupControlMean <- exp(groupDF$mean[1] + groupDF$mean[6] * abstBaseline) 
groupControlType <- rep("control", length(groupControlMean))
groupControl <- data.frame(abst = abstBaseline, low = groupControlLow,
                           high = groupControlHigh, mean = groupControlMean, 
                           typeChar = groupControlType,
                           group = rep(groups[i], length(groupControlMean)))

groupEmpLow <- exp(groupDF$low[2] + groupDF$low[5] * abstBaseline) 
groupEmpHigh <- exp(groupDF$high[2] + groupDF$high[5] * abstBaseline) 
groupEmpMean <- exp(groupDF$mean[2] + groupDF$mean[5] * abstBaseline) 
groupEmpType <- rep("empathy", length(groupEmpMean))

groupEmp <- data.frame(abst = abstBaseline, low = groupEmpLow,
                           high = groupEmpHigh, mean = groupEmpMean,
                       typeChar = groupEmpType,
                       group = rep(groups[i], length(groupEmpMean)))

groupNormLow <- exp(groupDF$low[3] + groupDF$low[4] * abstBaseline) 
groupNormHigh <- exp(groupDF$high[3] + groupDF$high[4] * abstBaseline) 
groupNormMean <- exp(groupDF$mean[3] + groupDF$mean[4] * abstBaseline) 
groupNormType <- rep("normative", length(groupNormMean))

groupNorm <- data.frame(abst = abstBaseline, low = groupNormLow,
                       high = groupNormHigh, mean = groupNormMean,
                       typeChar = groupNormType, 
                       group = rep(groups[i], length(groupControlMean)))

groupJoint <- rbind(groupControl, groupEmp, groupNorm)

groupedPredictions[[i]]  <- groupJoint 
}

groupedPredictionsDF <- data.frame(do.call(rbind, groupedPredictions))



dfVisInd$userIndex <- as.integer(as.factor(dfVisInd$user))

jointLow <- numeric(440)
jointHigh <- numeric(440)
jointMean <- numeric(440)
jointAbst <- numeric(440)
jointUserIndex <- numeric(440)
jointType <- numeric(440)
for (index in 1:440){
    userDF <- dfVisInd[dfVisInd$userIndex == index,]
    userDF
    jointLow[index] <- exp(userDF$low[1] + userDF$low[2] * userDF$abst[2])
    jointHigh[index] <- exp(userDF$high[1] + userDF$high[2] * userDF$abst[2])
    jointMean[index] <- exp(userDF$mean[1] + userDF$mean[2] * userDF$abst[2])
    jointAbst[index] <- userDF$abst[1]
    jointUserIndex[index] <- userDF$userIndex[1]
    jointType[index] <-    userDF$type[1]
}

jointInd <- data.frame(userIndex = jointUserIndex, 
                       abst = jointAbst,
                       type = jointType, 
                       low = jointLow, 
                       mean = jointMean,
                       high = jointHigh)

jointInd$typeChar <- ifelse(jointInd$type == 3, "normative",
                            ifelse(jointInd$type == 2, "empathy", "control" ))

individualLeft <- ggplot(jointInd)+ 
  geom_pointrange(data = jointInd, aes(x = abst, y  = mean,
                                     ymin = low, ymax = high),
                  size = .3, color = "grey30",
                  position = position_jitter(width = 0.1), alpha = .4)+
  facet_wrap(~typeChar) +
  labs(title = "Multiplicative impact of cumulative  interventions")+
  xlab("aggression before (standardized)")+ ylab("multiplicative impact")+
  theme_tufte()+theme(plot.title.position = "plot")  

individualRight <- ggplot(jointInd)+facet_wrap(~typeChar)+
  geom_hline(aes(yintercept = 1), color = "black",
             alpha = 0.7, lty =2, size =.5)+
  geom_pointrange(data = jointInd, aes(x = abst, 
             y  = mean, ymin = low, ymax = high),
             size = .3, color = "grey30", alpha = .4,
             position = position_jitter(width = 0.1))+
  xlim(-.9,1.2)+ylim(0.5,1.7)+
  labs(title = " ",
       subtitle = "x axis restricted to the bulk of the sample (colored by random groups)")+
  xlab("aggression before (standardized)")+ ylab("multiplicative impact")+
  theme_tufte()+
  geom_line(data = groupedPredictionsDF, aes(x = abst, y = mean, 
                  color = group))+
  geom_errorbar(data = groupedPredictionsDF, 
        aes(x = abst, ymin = low, ymax = high, color = group), alpha = .1)+ 
  guides(color = FALSE) +theme(plot.title.position = "plot")
```





\begin{figure}[H]
```{r fig:cumulativeResultsPlot,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
individualLeft

individualRight
```
\caption{Multiplicative impact of cumulative interventions lag 3 on attacks. Individual users' coefficents only, full range (top), and with attention restricted to the bulk of the sample. Sub-sample coefficients depend on aggression and are represented as lines, colored by sub-sample. Note low number and high uncertainty for highly aggressive users, which motivate the restriction of the $x$ axis for inspection.}
\label{fig:cumulativeResultsPlot}
\end{figure}
  
\normalsize 
The efficiency of normative interventions seems overall higher, except for low-aggression users, for  which empathetic interventions might be equally or more useful. Importantly, linear extrapolation to extreme values might be misleading, so let us inspect on what happens with the general level multiplicative coefficients at the levels of aggression which are actually quite common, that is, at the 1st, 2nd and 3rd quartile (with respect to $\mathsf{abst}$). This indicates that for the bulk of the sample the impact of cumulative interventions has been negative, slightly more so on users with lower aggression levels.







\footnotesize
```{r cumulativeResultsGeneral,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE, tidy = FALSE}
hateJointDF <- do.call(rbind,hateDFs)
quantile(hateJointDF$ABS, c(.25, .5, .75))

groupedQuantiled <- groupedPredictionsDF[groupedPredictionsDF$abst == -.56 | 
                                        groupedPredictionsDF$abst == -.26 | 
      (groupedPredictionsDF$abst < 0.178 & groupedPredictionsDF$abst >= 0.16),]


groupedQuantiled$quantile <- ifelse( groupedQuantiled$abst == -.56, .25, 
                                     ifelse(groupedQuantiled$abst == -.26, .5,
                                            .75)
)


plotGeneralCumulative <- ggplot(groupedQuantiled)+ 
  geom_pointrange(aes(x = as.factor(quantile), y  = mean, ymin = low,
                  ymax = high, color = group), size = .4, alpha = 1, 
                  position = position_dodge(width = 0.4))+
  facet_wrap(~typeChar)+xlab("aggression before (quantile)")+
  ylab("coefficient")+theme_tufte()+ guides(color = "none")+
  labs(title = "Multiplicative impact of cumulative interventions in
                  three aggression quantiles")+
  geom_hline(aes(yintercept = 1), color = "black", 
                  alpha = 0.7, lty =2, size =.5)+
  geom_label_repel(aes(x = as.factor(quantile), y  = mean,
                  label = round(mean,2), color = group), size = 3) +
  theme(plot.title.position = "plot")
```

\normalsize


\begin{figure}[H]
```{r fig:cumulativeResultsGeenralPlot,echo=FALSE,eval=TRUE,fig.align = "center", cache=TRUE, fig.show = "hold", out.width = "100%",   message = FALSE, warning = FALSE, results = FALSE}
plotGeneralCumulative 
```
\caption{Multiplicative impact of cumulative interventions lag 3 on attacks. General level coefficents only, in three quantiles (.25, .5, .75). Colored by sub-sample.}
\label{fig:cumulativeResultsGeneralPlot}
\end{figure}



## Long term before/after analysis





The coefficient in the  \textsf{Final} model are as in Figure
\ref{fig:coeffs}.

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=FALSE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
FinalHMC <- ulam(
  alist(
    AdiffS ~ dnorm( mu, sigma ),
    mu <- a + bADS[groupID] * ADS +  bIT[groupID] +
    bIC[groupID] * IC + bADSIC * ADS * IC+
    bCBS[groupID] *CBS,
    a ~ dnorm (0,0.3),
    bADS[groupID] ~ dnorm(0,.3),
    bADSIC ~ dnorm(0,.3),
    bCBS[groupID] ~ dnorm(0,.3),
    bIT[groupID] ~ dnorm(0,.3),
    bIC[groupID] ~ dnorm(0,.3),
    sigma  ~ dexp(1)
  ),
  data = summaries
)
```

```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
FinalHMC <- readRDS(file = "models/FinalHMC.rds")
```


\begin{figure}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
plot(precis(FinalHMC, depth = 2))
```
\caption{The final model coefficients.}
\label{fig:coeffs}
\end{figure}

\normalsize



The general problem is that in models of this complexity involving interaction, these are hard to interpret. For this reason, it is better to plot predicted effects for various combinations of predictors. In the construction of the plots we rely on   the following:
\begin{itemize}
\item The values \textsf{ADS} range from -.67 to 10, with approximately 30\% below -.5, around 80\% below .3, and around 95\% below 1.7, so we use these three settings of this variable in our visualizations. 

\item The values \textsf{CBS} range from -.82 to 18.3, with approximately 30\% below -.4, around 80\% below .3, and around 95\% below 1.3, so we use these three settings of this variable in our visualizations. 


\end{itemize}

\footnotesize

```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
visGroup <-function(model, ADS, CBS, IC, xmin = 2, ymax = -3){
      groupID <- 1:3
      data <- expand.grid(ADS = ADS, groupID = groupID,
                          CBS = CBS, IC = IC)
      posterior <- extract.samples(model, n = 1e+05)
      mu <- link(model, data = data)
      colnames(mu) <- levels(summaries$group)
      muLong <- melt(mu)
      colnames(muLong) <- c("id", "group", "AdiffS")
      means <- round(apply(mu, 2, mean), 2)
      mu_HPDI <- round(apply(mu, 2, HPDI), 2)
      means <- as.data.frame(means)
      means$group <- rownames(means)
      rownames(means) <- NULL
      meansDisp <- cbind(means, t(as.data.frame(mu_HPDI)))
      meansDisp <- meansDisp[, c(1, 3, 4)]
      at <- c(-2, -1, 0, 1, 2)
      labels <- at * sd(summaries$AdiffS)+     
      mean(summaries$AdiffS)

  plot <- ggplot(muLong) + 
      geom_violin(aes(x = group, color = group, y = AdiffS), alpha = 0.2) +
      xlab("") + scale_y_continuous(breaks = labels) +   
  scale_color_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
      ylab("predicted difference in attacks") +
    guides(color = "none")+
      labs(title = paste("ADS=", ADS, ", CBS=",
                          CBS, sep = "")) +   
      theme_tufte(base_size = 7) +
      ylim(c(-2, 2))
return(plot)
}

destandardize <- function(value, base) {
    round(value * sd(base) + mean(base), 1)
}

visGroupRight <- function(model, ADS, CBS, xmin = 2, ymax = -3, 
                          at = c(-2,-1, 0, 1, 2), base, basename) {
      groupID <- 1:3
      IC <- 5
      data <- expand.grid(ADS = ADS, groupID = groupID, CBS = CBS, IC = IC)
      posterior <- extract.samples(model, n = 1e+05)
      mu <- link(model, data = data)
      colnames(mu) <- levels(summaries$group)
      muLong <- melt(mu)
      colnames(muLong) <- c("id", "group", "AdiffS")
      means <- round(apply(mu, 2, mean), 2)
      mu_HPDI <- round(apply(mu, 2, HPDI), 2)
      means <- as.data.frame(means)
      means$group <- rownames(means)
      rownames(means) <- NULL
      meansDisp <- cbind(means, t(as.data.frame(mu_HPDI)))
      meansDisp <- meansDisp[, c(1, 3, 4)]
      labs <- destandardize(at, base)
  plot <- ggplot(muLong) + 
          geom_violin(aes(x = group, color = group, y = AdiffS), alpha = 0.2) +
          xlab("") + labs(title = paste("ADS=", ADS, ", CBS=", CBS, sep = "")) +
          theme_tufte(base_size = 7) +   
  scale_color_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
    guides(color = "none")

  plot <- plot + ylim(at[1], tail(at, 1)) +
        scale_y_continuous(breaks = NULL, labels = NULL, name = NULL,
                          sec.axis = sec_axis(~. * sd(base) + mean(base),
                          name = basename, breaks = c(labs, 0)), 
                          limits = c(at[1], tail(at, 1)))
  return(plot)
}


visGroupA5C4  <- visGroup(model = FinalHMC, ADS = -0.5, CBS = -0.4, IC = 5)
visGroupA5C3  <- visGroup(model = FinalHMC, ADS = -0.5, CBS = 0.3, IC = 5)
visGroupA5C13 <- visGroupRight(model = FinalHMC, ADS = -0.5, CBS = 1.3,
                 base = summaries$Adiff, basename = "Adiff")
visGroupA3C4  <- visGroup(model = FinalHMC, ADS = 0.3, CBS = -0.4, IC = 5)
visGroupA3C3  <- visGroup(model = FinalHMC, ADS = 0.3, CBS = 0.3, IC = 5)
visGroupA3C13 <- visGroupRight(model = FinalHMC, ADS = 0.3, CBS = 1.3,
                 base = summaries$Adiff, basename = "Adiff")
visGroupA17C4 <- visGroup(model = FinalHMC, ADS = 1.7, CBS = -0.4, IC = 5)
visGroupA17C3 <- visGroup(model = FinalHMC, ADS = 1.7, CBS = 0.3, IC = 5)
visGroupA17C13 <- visGroupRight(model = FinalHMC, ADS = 1.7, CBS = 1.3,
                 base = summaries$Adiff, basename = "Adiff")

visGroupJoint <- ggarrange(
      visGroupA17C4 + ylab("ADS = 1.7") + removeX +
      ggtitle("CBS = -.4"), 
      visGroupA17C3 + removeY + removeX + ggtitle("CBS = .3"), 
      visGroupA17C13 + removeX + ggtitle("CBS = 1.3"),
      visGroupA3C4 + removeX + ylab("ADS = .3") + ggtitle(""), 
      visGroupA3C3 + ggtitle("") + removeX + removeY,
      visGroupA3C13 + ggtitle("") + removeX,
      visGroupA5C4 + ylab("ADS = -.5") + ggtitle(""),
      visGroupA5C3 + removeY + ggtitle(""),
      visGroupA5C13 + ggtitle(""), ncol = 3, nrow = 3
      )
visGroupJoint2b <- annotate_figure(visGroupJoint, 
      top = text_grob(
  "(standardized (left) and original scale (right),IC at the rounded mean = 5)",
  size = 10))
visGroupJoint3b <- annotate_figure(visGroupJoint2b, 
top = text_grob(
    "Predicted change in attacks by activity level and treatment groups",
    size = 12))

```


Grouped before-and-after predicted change of attacks by the levels we just listed are visualized in Figure \ref{fig:predictedChange}.

\begin{figure}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
visGroupJoint3b
```
\caption{Predicted change in attacks, depending on user’s activity level
(CBS: comments before, standardized) and how aggressive overall they
were (ADS: attacks during, standardized). The more aggressive and active
the users, the higher the attacks drop in the normative group, slight drop
correlated with emotive interventions for not too active users.}
\label{fig:predictedChange}
\end{figure}

\normalsize


For more clarity, let’s inspect predicted contrasts, here understood as distances from
the control group mean, by activity level, first versus CBS (comments before, standardized, Figure \ref{fig:ContrastCBS}), then versus ADS (attacks during, standardized, Figure \ref{fig:ContrastADS}).



\footnotesize

```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}

visContrastsCBS <- function(model = FinalHMC, ADS = ADS, IC = 5,
                    CBS = seq(-0.5, 1.5, by = 0.1)) {
      groupID <- 1:3
      data <- expand.grid(ADS, groupID, IC, CBS)
      colnames(data) <- c("ADS", "groupID", "IC", "CBS")
      posterior <- extract.samples(model, n = 1e+05)
      mu <- link(model, data = data)
      means <- round(apply(mu, 2, mean), 4)
      HPDIs <- round(apply(mu, 2, HPDI), 4)
      visContrast <- cbind(data, means, t(as.data.frame(HPDIs)))

      ones <- 3 * (1:(nrow(visContrast)/3)) - 2
      twos <- 3 * (1:(nrow(visContrast)/3)) - 1
      threes <- 3 * (1:(nrow(visContrast)/3))

      colnames(visContrast)[c(6, 7)] <- c("low", "high")
      contrast <- numeric(nrow(visContrast))
      cLow <- numeric(nrow(visContrast))
      cHigh <- numeric(nrow(visContrast))

      for (i in threes) {
                contrast[i] <- visContrast$means[i] - visContrast$means[i - 2]
      }
      
      for (i in twos) {
                contrast[i] <- visContrast$means[i] - visContrast$means[i - 1]
      }
      visContrast$contrast <- contrast
      visContrast$shift <- visContrast$contrast - visContrast$means

      for (i in ones) {
            visContrast$shift[i] <- 0
      }
      visContrast$cLow <- visContrast$low + visContrast$shift
      visContrast$cHigh <- visContrast$high + visContrast$shift
      visContrast$group = rep(c("control", "empathy", "normative"), 
                              nrow(visContrast)/3)
      visContrastTreatment <- visContrast[groupID != 1, ]

    return(ggplot(visContrastTreatment,
         aes(x = CBS, y = contrast, fill = group, lty = group)) +
         geom_line(se = FALSE) + 
         geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), alpha = 0.3) +
         theme_tufte(base_size = 7))+
        scale_fill_manual(values=c("dodgerblue4", "orangered"))
      
}

visContrastsCBSright <- function(model = FinalHMC, ADS = ADS, IC = 5,
                              CBS = seq(-0.5, 1.5, by = 0.1), 
                              at = c(-2, -1, 0, 1, 2), base, basename) {
      labs <- destandardize(at, base)
      groupID <- 1:3
      data <- expand.grid(ADS, groupID, IC, CBS)
      colnames(data) <- c("ADS", "groupID", "IC", "CBS")
      posterior <- extract.samples(model, n = 1e+05)
      mu <- link(model, data = data)
      means <- round(apply(mu, 2, mean), 4)
      HPDIs <- round(apply(mu, 2, HPDI), 4)
      visContrast <- cbind(data, means, t(as.data.frame(HPDIs)))
      colnames(visContrast)[c(6, 7)] <- c("low", "high")

      ones <- 3 * (1:(nrow(visContrast)/3)) - 2
      twos <- 3 * (1:(nrow(visContrast)/3)) - 1
      threes <- 3 * (1:(nrow(visContrast)/3))
      colnames(visContrast)[c(6, 7)] <- c("low", "high")
      contrast <- numeric(nrow(visContrast))
      cLow <- numeric(nrow(visContrast))
      cHigh <- numeric(nrow(visContrast))

      for (i in threes) {
          contrast[i] <- visContrast$means[i] - visContrast$means[i - 2]
      }
      
      for (i in twos) {
            contrast[i] <- visContrast$means[i] - visContrast$means[i - 1]
      }
      visContrast$contrast <- contrast
      visContrast$shift <- visContrast$contrast - visContrast$means

      for (i in ones) {
          visContrast$shift[i] <- 0
      }
    
      visContrast$cLow <- visContrast$low + visContrast$shift
      visContrast$cHigh <- visContrast$high + visContrast$shift
      visContrast$group = rep(c("control", "empathy", "normative"), 
                              nrow(visContrast)/3)
      visContrastTreatment <- visContrast[groupID != 1, ]

      plot <- ggplot(visContrastTreatment, aes(x = CBS, y = contrast, 
                                    fill = group, lty = group)) + geom_line() +
        geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), alpha = 0.3) + 
        theme_tufte(base_size = 7)+
        scale_fill_manual(values=c("dodgerblue4", "orangered"))
      
      plot <- plot + ylim(at[1], tail(at,1))
      plot <- plot + scale_y_continuous(breaks = NULL, labels = NULL, name = NULL,
              sec.axis = sec_axis(~.*sd(base)+ mean(base), 
                         name = basename, breaks = c(labs,0)),
              limits = c(at[1], tail(at,1)))
return(plot)
}

vcCBSa <-  visContrastsCBS(FinalHMC, ADS = -0.5) + ggtitle("ADS = -.5") +
                  ylim(c(-1.5, 2)) +  
        scale_fill_manual(values=c("dodgerblue4", "orangered"))+ 
                 guides(lty = "none", fill = "none")
 
vcCBSb <-  visContrastsCBS(FinalHMC, ADS = 0.3) + ggtitle("ADS = .3") + ylim(c(-1.5, 2)) +
        scale_fill_manual(values=c("dodgerblue4", "orangered"))+
        guides(lty = "none", fill  = "none") +
                  removeY
 
vcCBSc <-  visContrastsCBSright(FinalHMC, ADS = 1.7, at = c(-1.5, -1, -0.5, 0, 0.5, 1, 1.5),
                       base = summaries$Adiff, basename = "count") +
                  ggtitle("ADS = 1.7") +
                  theme(legend.position = c(0.75, 0.15))

vcCBS1 <- ggarrange(vcCBSa, vcCBSb, vcCBSc, ncol = 3)
 
vcCBS2 <- annotate_figure(vcCBS1, top = text_grob(
           "(IC at the rounded mean = 5)",  size = 10))

vcCBS3 <- annotate_figure(vcCBS2,
            top = text_grob(
            "Predicted distance from the control group mean vs. CBS (standardized)",
size = 12))

```
\normalsize



\begin{figure}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
vcCBS3
```
\caption{Predicted contrasts (difference in attacks as compared to the control group)
for the two treatment groups vs activity before the treatment. Notice that
empathetic interventions correlated with decreased attacks for less active
users, but performed worse than normative interventions for more active
users. Normative interventions, in contrast, seem to have better impact on
 more active users.}
\label{fig:ContrastCBS}
\end{figure}

\normalsize



\footnotesize

```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
visContrastsADS <- function(model = FinalHMC, CBS = CBS, IC = 5,
                            ADS = seq(-0.5, 1.8, by = 0.1)) {
      data <- expand.grid(CBS, groupID, IC, ADS)
      colnames(data) <- c("CBS", "groupID", "IC", "ADS")
      posterior <- extract.samples(model, n = 1e+05)
      mu <- link(model, data = data)
      means <- round(apply(mu, 2, mean), 4)
      HPDIs <- round(apply(mu, 2, HPDI), 4)
      visContrastADS <- cbind(data, means, t(as.data.frame(HPDIs)))
      ones <- 3 * (1:(nrow(visContrastADS)/3)) - 2
      twos <- 3 * (1:(nrow(visContrastADS)/3)) - 1
      threes <- 3 * (1:(nrow(visContrastADS)/3))
      colnames(visContrastADS)[c(6, 7)] <- c("low", "high")
      contrastADS <- numeric(nrow(visContrastADS))
      for (i in threes) {
          contrastADS[i] <- visContrastADS$means[i] - visContrastADS$means[i -2]
      }
      for (i in twos) {
          contrastADS[i] <- visContrastADS$means[i] - visContrastADS$means[i - 1]
      }
      visContrastADS$contrast <- contrastADS
      visContrastADS$shift <- visContrastADS$contrast - visContrastADS$means
      for (i in ones) {
          visContrastADS$shift[i] <- 0
      }
      visContrastADS$cLow <- visContrastADS$low + visContrastADS$shift
      visContrastADS$cHigh <- visContrastADS$high + visContrastADS$shift
      visContrastADS$group = rep(c("control", "empathy", "normative"), nrow(visContrastADS)/3)
      visContrastTreatmentADS <- visContrastADS[groupID != 1, ]

return(
      ggplot(visContrastTreatmentADS,  aes(x = ADS, y = contrast, fill = group, lty = group)) +
         geom_line(se = FALSE) +
         geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), alpha = 0.3) +
         theme_tufte(base_size = 7) + guides(lty = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered"))
      )

}

visContrastsADSright <- function(model = FinalHMC, CBS = CBS, IC = 5,
  ADS = seq(-0.5, 1.8, by = 0.1), at = c(-1.5, 1, 0, 1, 1.5), base, basename) {
      labs <- destandardize(at, base)
      data <- expand.grid(CBS, groupID, IC, ADS)
      colnames(data) <- c("CBS", "groupID", "IC", "ADS")
      posterior <- extract.samples(model, n = 1e+05)
      mu <- link(model, data = data)
      means <- round(apply(mu, 2, mean), 4)
      HPDIs <- round(apply(mu, 2, HPDI), 4)
      visContrastADS <- cbind(data, means, t(as.data.frame(HPDIs)))
      ones <- 3 * (1:(nrow(visContrastADS)/3)) - 2
      twos <- 3 * (1:(nrow(visContrastADS)/3)) - 1
      threes <- 3 * (1:(nrow(visContrastADS)/3))
      colnames(visContrastADS)[c(6, 7)] <- c("low", "high")
      contrastADS <- numeric(nrow(visContrastADS))
      for (i in threes) {
          contrastADS[i] <- visContrastADS$means[i] - visContrastADS$means[i-2]
      }
      for (i in twos) {
          contrastADS[i] <- visContrastADS$means[i] - visContrastADS$means[i-1]
      }
      visContrastADS$contrast <- contrastADS
      visContrastADS$shift <- visContrastADS$contrast - visContrastADS$means
      for (i in ones) {
      visContrastADS$shift[i] <- 0
      }
      visContrastADS$cLow <- visContrastADS$low + visContrastADS$shift
      visContrastADS$cHigh <- visContrastADS$high + visContrastADS$shift
      visContrastADS$group = rep(c("control", "empathy", "normative"), nrow(visContrastADS)/3)
      visContrastTreatmentADS <- visContrastADS[groupID != 1, ]

  plot <- ggplot(visContrastTreatmentADS,
                 aes(x = ADS, y = contrast, fill = group, lty = group)) +
    geom_line(se = FALSE) +
    scale_fill_manual(values=c("dodgerblue4", "orangered"))+
    geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), alpha = 0.3) +
    theme_tufte(base_size = 7) + guides(lty = "none")

  plot <- plot + ylim(at[1], tail(at, 1))
  plot <- plot + scale_y_continuous(breaks = NULL, labels = NULL, name = NULL,
        sec.axis = sec_axis(~. * sd(base) + mean(base), name = basename,
        breaks = c(labs, 0)), limits = c(at[1], tail(at, 1)))
}

vcADSa <- visContrastsADS(FinalHMC, CBS = -0.4) + ggtitle("CBS = -.4") +
      ylim(c(-1.5, 1.5)) + 
      guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered"))

vcADSb <-  visContrastsADS(FinalHMC, CBS = 0.3) + ggtitle("CBS = .3") +
      ylim(c(-1.5, 1.5)) + scale_fill_discrete(guide = "none") +
      removeY + guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered"))
 
vcADSc <- visContrastsADSright(FinalHMC, CBS = 1.3, at = c(-1.5, -1, 0, 1, 1.5),
      base = summaries$Adiff, basename = "count") + ggtitle("CBS = 1.3") +
      theme(legend.position = c(0.75, 0.15))

vcADS1 <- ggarrange(
vcADSa, vcADSb, vcADSc,
ncol = 3)
 
vcADS2 <- annotate_figure(vcADS1, top = text_grob(
  "(IC at the rounded mean = 5)", size = 10))

vcADS3 <- annotate_figure(vcADS2, top = text_grob(
   "Predicted distance from the control group mean vs. ADS",
 size = 12))
```



\begin{figure}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
vcADS3
```
\caption{Predicted contrasts (difference in attacks as compared to the control group)
for the two treatment groups vs aggression during the treatment period.
Notice that empathetic interventions correlated with decreased attacks for
less aggressive users, but performed worse than normative interventions for
more aggressive users. Normative interventions, in contrast, seem to have
better impact on  more aggressive users.}
\label{fig:ContrastADS}
\end{figure}

\normalsize


Now, let’s inspect the impact of intervention counts by treatment type by looking at
contrasts (distances from the control group mean) with 89\% HPDIs by IC (intervention
count). Notice the predicted effect of IC is weaker than group membership, so for
visibility the $y$-axis has a smaller range. Also, not enough data was available to reliably
estimate uncertainty for IC above 20, hence the restriction on the $x$-axis (already at
lower values, lack of estimates is visible for the more extreme settings).



\footnotesize

```{r visIC,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
visContrastsIC <- function(model = FinalHMC, CBS = CBS ,
                           IC = seq(0,20,by = 1), ADS = ADS) {
    groupID <- 1:3
    data <- expand.grid(CBS, groupID, IC , ADS)
    colnames(data) <- c("CBS", "groupID", "IC", "ADS")
    posterior <- extract.samples(model, n = 1e5)
    mu <- link( model, data=data )
    means <- round(apply(mu , 2 , mean ), 4)
    HPDIs <- round(apply( mu , 2 , HPDI ),4)
    visContrastIC <- cbind(data,means,t(as.data.frame(HPDIs)))
    ones <- 3 * (1:(nrow(visContrastIC)/3))-2
    twos <- 3 * (1:(nrow(visContrastIC)/3))-1
    threes <- 3 * (1:(nrow(visContrastIC)/3))
    colnames(visContrastIC)[c(6,7)] <- c("low", "high")
    contrastIC <- numeric(nrow(visContrastIC))
    for(i in threes){
        contrastIC[i] <- visContrastIC$means[i] - visContrastIC$means[i-2]
      }
    for(i in twos){
        contrastIC[i] <- visContrastIC$means[i] - visContrastIC$means[i-1]
      }
    visContrastIC$contrast <- contrastIC
    visContrastIC$shift <- visContrastIC$contrast - visContrastIC$means
    for(i in ones){
        visContrastIC$shift[i] <- 0
    }
    visContrastIC$cLow <- visContrastIC$low + visContrastIC$shift
    visContrastIC$cHigh <- visContrastIC$high + visContrastIC$shift
    visContrastIC$group = rep(c("control", "empathy", "normative"),
        nrow(visContrastIC)/3)
    visContrastTreatmentIC <- visContrastIC[groupID !=1,]

return(ggplot(visContrastTreatmentIC,
        aes(x = IC, y = contrast, fill = group, lty = group ))+
         scale_fill_manual(values=c("darkgreen", "dodgerblue4", "orangered"))+
        geom_line(se=FALSE)+
        geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), alpha = .3)+
        ylim(c(-1.2,1)) +theme_tufte(base_size = 7))

}

visContrastsICright <- function(model = FinalHMC, CBS = CBS ,
    IC = seq(0,20,by = 1), ADS = ADS, at = c(-1,.5,0,.5,1), base, basename){
      labs <- destandardize(at, base)
      groupID <- 1:3
      data <- expand.grid(CBS, groupID, IC , ADS)
      colnames(data) <- c("CBS", "groupID", "IC", "ADS")
      posterior <- extract.samples(model, n = 1e5)
      mu <- link( model, data=data )
      means <- round(apply(mu , 2 , mean ), 4)
      HPDIs <- round(apply( mu , 2 , HPDI ),4)
      visContrastIC <- cbind(data,means,t(as.data.frame(HPDIs)))
      ones <- 3 * (1:(nrow(visContrastIC)/3))-2
      twos <- 3 * (1:(nrow(visContrastIC)/3))-1
      threes <- 3 * (1:(nrow(visContrastIC)/3))

    colnames(visContrastIC)[c(6,7)] <- c("low", "high")
    contrastIC <- numeric(nrow(visContrastIC))
    for(i in threes){
        contrastIC[i] <- visContrastIC$means[i] - visContrastIC$means[i-2]
        }
    for(i in twos){
        contrastIC[i] <- visContrastIC$means[i] - visContrastIC$means[i-1]
        }
    visContrastIC$contrast <- contrastIC
    visContrastIC$shift <- visContrastIC$contrast - visContrastIC$means
    for(i in ones){
        visContrastIC$shift[i] <- 0
      }
    visContrastIC$cLow <- visContrastIC$low + visContrastIC$shift
    visContrastIC$cHigh <- visContrastIC$high + visContrastIC$shift
    visContrastIC$group = rep(c("control", "empathy", "normative"),
        nrow(visContrastIC)/3)
    visContrastTreatmentIC <- visContrastIC[groupID !=1,]

  plot <- ggplot(visContrastTreatmentIC,
                   aes(x = IC, y = contrast, fill = group, lty = group ))+
    scale_fill_manual(values=c("dodgerblue4", "orangered"))+
    geom_line(se=FALSE)+
    geom_ribbon(mapping = aes(ymin = cLow, ymax = cHigh), alpha = .3)+
    theme_tufte(base_size = 7)

  plot <- plot+ylim(at[1],tail(at,1))
  plot <- plot+scale_y_continuous(breaks = NULL, labels = NULL,
        name = NULL, sec.axis= sec_axis(~. * sd(base) + mean(base),
        name = basename, breaks = c(labs,0)),
        limits = c(at[1]-.2,tail(at,1)))
}


visContrastsICJointD <- ggarrange(
    visContrastsIC(ADS = 1.7, CBS = -.4)+removeX+
          theme(legend.position = c(0.3, 0.9),
          legend.key.size = unit(.3, 'cm'),
          legend.key.height = unit(.3, 'cm'),
          legend.key.width = unit(.3, 'cm'),
          legend.title= element_blank())+
          ggtitle("CBS = -.4")+ ylab("ADS = 1.7")+ guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered")),
    visContrastsIC(ADS = 1.7, CBS = .3)+removeY+removeX+
          scale_fill_discrete(guide="none")+
          ggtitle("CBS = .3")+ guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered")),
    visContrastsICright(ADS = 1.7, CBS = 1.3, at = c(-2,-1,0,1,2),
                        base = summaries$Adiff, basename = "count")+
          removeX + guides(lty = "none", fill = "none")+
          ggtitle("CBS = 1.3"),
    visContrastsIC(ADS = .3, CBS = -.4)+removeX+
          scale_fill_discrete(guide="none")+
          ylab("ADS = .3")+ guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered")),
    visContrastsIC(ADS = .3, CBS = .3)+removeY+removeX+
           guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered")),
    visContrastsICright(ADS = .3, CBS = 1.3,at = c(-2,-1,0,1,2),
          base = summaries$Adiff, basename = "count")+
          removeX  + guides(lty = "none", fill = "none"),
    visContrastsIC(ADS = -.5, CBS = -.4)+
          ylab("ADS = -.5")+ guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered")),
    visContrastsIC(ADS = -.5, CBS = .3)+removeY+
      guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered")),
    visContrastsICright(ADS = -.5, CBS = 1.3,at = c(-2,-1,0,1,2),
                        base = summaries$Adiff, basename = "count") +
      guides(lty = "none", fill = "none")+
      scale_fill_manual(values=c("dodgerblue4", "orangered")),
  ncol = 3, nrow = 3
)

visContrastsICJoint2D <- annotate_figure(visContrastsICJointD,
top = text_grob("", size = 10))
visContrastsICJoint3D <- annotate_figure(visContrastsICJoint2D,
top = text_grob("Predicted distance from the control group vs. IC",
size = 12))
```




\begin{figure}
```{r visICPlot,echo=FALSE,eval=TRUE,fig.align = "center",cache=FALSE, fig.show = "hold", out.width = "100%"}
visContrastsICJoint3D
```
\caption{Contrasts (change in attacks as compared to the control group) vs the number
of interventions received. Note that repeating empathetic interventions
correlates with decreased attacks, while repeating normative interventions
is counterproductive.}
\label{fig:ContrastsIC}
\end{figure}

